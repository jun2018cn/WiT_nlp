{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. spaCy basics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "spaCy is an open-source software library for advanced natural language processing, written in the programming languages Python and Cython.The library is published under the MIT license and currently offers statistical neural network models for English, German, Spanish, Portuguese, French, Italian, Dutch and multi-language NER, as well as tokenization for various other languages.$^{1}$\n",
    "\n",
    "https://spacy.io/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installation and setup \n",
    "\n",
    "1. First we need to download the spaCy library:\n",
    "    > `conda install -c conda-forge spacy`\n",
    "    > <br>*or*<br>\n",
    "    > `pip install -U spacy`\n",
    "2. Then, we download the language model we want to use:\n",
    "    > `python -m spacy download en_core_web_lg`\n",
    "    > <br>*alternatively*<br>\n",
    "    > `import spacy.cli` <br>\n",
    "    >  `spacy.cli.download(\"en_core_web_lg\") `\n",
    "3. Finally, you load the model:\n",
    "    > `spacy.load('en_core_web_lg')`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the model via spacy.load('en_core_web_lg')\n"
     ]
    }
   ],
   "source": [
    "import spacy.cli\n",
    "spacy.cli.download(\"en_core_web_lg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import spaCy\n",
    "import spacy\n",
    "\n",
    "# load the language model\n",
    "nlp = spacy.load('en_core_web_lg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The DET det\n",
      "quick ADJ amod\n",
      "brown ADJ amod\n",
      "fox PROPN nsubj\n",
      "jumps VERB ROOT\n",
      "over ADP prep\n",
      "the DET det\n",
      "lazy ADJ amod\n",
      "dog NOUN pobj\n",
      "! PUNCT punct\n"
     ]
    }
   ],
   "source": [
    "# Create a Doc object\n",
    "doc = nlp(u\"The quick brown fox jumps over the lazy dog!\")\n",
    "\n",
    "# Print each token separately\n",
    "for token in doc:\n",
    "    print(token.text, token.pos_, token.dep_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'punctuation'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get a description for a given POS tag, dependency label or entity type\n",
    "\n",
    "spacy.explain('PUNCT')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Pipeline\n",
    "When we call `nlp` on our string, we are creating a `DOC` object which is \n",
    "basically an array of token objects made from that string. We can then perform a series of operations on that tokens in order to dercribe the data.   <br>Image source: https://spacy.io/usage/spacy-101#pipelines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"img/pipeline1.png\" width=\"600\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('tagger', <spacy.pipeline.pipes.Tagger at 0x11b4d4c18>),\n",
       " ('parser', <spacy.pipeline.pipes.DependencyParser at 0x11bf68c48>),\n",
       " ('ner', <spacy.pipeline.pipes.EntityRecognizer at 0x11bf68ca8>)]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp.pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenization\n",
    "\n",
    "This is usually the first step in Natural Language Processing. Tokenization means 'chopping' the text into pieces in order to create tokens. Since we are using spaCy with a pretrained language model, these tokens also contain some descriptive information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['While', 'Amazon', 'CEO', 'Jeff', 'Bezos', \"wasn't\", 'throwing', 'a', 'lavish', 'party', 'at', 'his', '$23', 'million', 'mansion', 'in', 'Washington,', 'DC']\n"
     ]
    }
   ],
   "source": [
    "# basic tokenization with a split() function\n",
    "text = \"While Amazon CEO Jeff Bezos wasn't throwing a lavish party at his $23 million mansion in Washington, DC\"\n",
    "print(text.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "While SCONJ mark\n",
      "Amazon PROPN compound\n",
      "CEO PROPN compound\n",
      "Jeff PROPN compound\n",
      "Bezos PROPN nsubj\n",
      "was AUX aux\n",
      "n't PART neg\n",
      "throwing VERB ROOT\n",
      "a DET det\n",
      "lavish ADJ amod\n",
      "party NOUN dobj\n",
      "at ADP prep\n",
      "his DET poss\n",
      "$ SYM quantmod\n",
      "23 NUM compound\n",
      "million NUM nummod\n",
      "mansion NOUN pobj\n",
      "in ADP prep\n",
      "Washington PROPN pobj\n",
      ", PUNCT punct\n",
      "DC PROPN appos\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(text)\n",
    "for token in doc:\n",
    "    print(token.text, token.pos_, token.dep_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For a full list of `Part Of Speech` Tags visit https://spacy.io/api/annotation#pos-tagging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice how `wasn't` has been split into two tokens. spaCy recognizes both the root verb is and the negation attached to it. Notice also that both the extended whitespace and the period at the end of the sentence are assigned their own tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tokens are pieces of the original text. That is, we don't see any conversion to word stems or lemmas (base forms of words) and we haven't seen anything about organizations/places/money etc. Tokens are the basic building blocks of a Doc object - everything that helps us understand the meaning of the text is derived from tokens and their relationship to one another."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "#### Dependencies\n",
    "We also see the syntactic dependencies assigned to each token. `Bezos` is identified as an `nsubj` or the ***nominal subject*** of the sentence.\n",
    "\n",
    "For a full list of Syntactic Dependencies visit https://spacy.io/api/annotation#dependency-parsing\n",
    "<br>A good explanation of dependencies can be found [here](https://nlp.stanford.edu/software/dependencies_manual.pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'nominal subject'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spacy.explain('nsubj')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Other token attributes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|Tag|Description|\n",
    "|:------|:------:|\n",
    "|`.text`|The original word text|\n",
    "|`.lemma_`|The base form of the word|\n",
    "|`.pos_`|The simple part-of-speech tag|\n",
    "|`.tag_`|The detailed part-of-speech tag|\n",
    "|`.shape_`|The word shape – capitalization, punctuation, digits|\n",
    "|`.is_alpha`|Is the token an alpha character?|\n",
    "|`.is_stop`|Is the token part of a stop list, i.e. the most common words of the language?|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Named Entity Recognition\n",
    "\n",
    "NER introduces another layer of context. The spaCy language model recognizes that certain tokens represent for example locations or organizations. \n",
    "https://spacy.io/usage/linguistic-features#named-entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Apple | to | build | a | Hong | Kong | factory | for | $ | 6 | million | \n",
      "----\n",
      "Apple - ORG - Companies, agencies, institutions, etc.\n",
      "Hong Kong - GPE - Countries, cities, states\n",
      "$6 million - MONEY - Monetary values, including unit\n"
     ]
    }
   ],
   "source": [
    "ner = nlp(u'Apple to build a Hong Kong factory for $6 million')\n",
    "\n",
    "for token in ner:\n",
    "    print(token.text, end=' | ')\n",
    "\n",
    "print('\\n----')\n",
    "\n",
    "for ent in ner.ents:\n",
    "    print(ent.text+' - '+ent.label_+' - '+str(spacy.explain(ent.label_)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll also see how spaCy can interpret the tokens combined `$23 million` as referring to ***money***."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualizing NER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy import displacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">By \n",
       "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    2010\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
       "</mark>\n",
       " standards, the \n",
       "<mark class=\"entity\" style=\"background: #bfeeb7; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    iPad\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">PRODUCT</span>\n",
       "</mark>\n",
       " was thin—\n",
       "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    half an inch\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">QUANTITY</span>\n",
       "</mark>\n",
       " thin—and weighed \n",
       "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    1.5 pounds\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">QUANTITY</span>\n",
       "</mark>\n",
       ". It had a capacitive multitouch display, ran on \n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Apple\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       "’s custom \n",
       "<mark class=\"entity\" style=\"background: #bfeeb7; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    A4\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">PRODUCT</span>\n",
       "</mark>\n",
       " chip, and offered \n",
       "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    10 hours\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">TIME</span>\n",
       "</mark>\n",
       " of battery life, something that would win it praise in early reviews. WIRED’s review noted that watching video on it was “terrific,” as was reading on it, and that the \n",
       "<mark class=\"entity\" style=\"background: #bfeeb7; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    iPad\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">PRODUCT</span>\n",
       "</mark>\n",
       " was well-positioned as a gaming platform. But the \n",
       "<mark class=\"entity\" style=\"background: #bfeeb7; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    iPad\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">PRODUCT</span>\n",
       "</mark>\n",
       " was also hamstrung in its earliest incarnation. It didn’t have a camera, it didn’t support multitasking, the \n",
       "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Safari\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
       "</mark>\n",
       " browsing experience was limited, and the virtual keyboard came with a learning curve</div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "doc = nlp(u'By 2010 standards, the iPad was thin—half an inch thin—and weighed 1.5 pounds. It had a capacitive multitouch display, ran on Apple’s custom A4 chip, and offered 10 hours of battery life, something that would win it praise in early reviews. WIRED’s review noted that watching video on it was “terrific,” as was reading on it, and that the iPad was well-positioned as a gaming platform. But the iPad was also hamstrung in its earliest incarnation. It didn’t have a camera, it didn’t support multitasking, the Safari browsing experience was limited, and the virtual keyboard came with a learning curve')\n",
    "displacy.render(doc, style='ent', jupyter=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualizing dependency parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(u'Apple is going to build a U.K. factory for $6 million.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" xml:lang=\"en\" id=\"6eb201bd729f45678b027c1f56ea10c7-0\" class=\"displacy\" width=\"1130\" height=\"317.0\" direction=\"ltr\" style=\"max-width: none; height: 317.0px; color: #000000; background: #ffffff; font-family: Arial; direction: ltr\">\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"227.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"50\">Apple</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"50\">PROPN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"227.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"140\">is</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"140\">AUX</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"227.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"230\">going</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"230\">VERB</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"227.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"320\">to</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"320\">PART</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"227.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"410\">build</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"410\">VERB</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"227.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"500\">a</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"500\">DET</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"227.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"590\">U.K.</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"590\">PROPN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"227.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"680\">factory</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"680\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"227.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"770\">for</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"770\">ADP</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"227.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"860\">$</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"860\">SYM</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"227.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"950\">6</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"950\">NUM</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"227.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1040\">million.</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1040\">NUM</tspan>\n",
       "</text>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-6eb201bd729f45678b027c1f56ea10c7-0-0\" stroke-width=\"2px\" d=\"M70,182.0 C70,92.0 220.0,92.0 220.0,182.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-6eb201bd729f45678b027c1f56ea10c7-0-0\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M70,184.0 L62,172.0 78,172.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-6eb201bd729f45678b027c1f56ea10c7-0-1\" stroke-width=\"2px\" d=\"M160,182.0 C160,137.0 215.0,137.0 215.0,182.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-6eb201bd729f45678b027c1f56ea10c7-0-1\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">aux</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M160,184.0 L152,172.0 168,172.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-6eb201bd729f45678b027c1f56ea10c7-0-2\" stroke-width=\"2px\" d=\"M340,182.0 C340,137.0 395.0,137.0 395.0,182.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-6eb201bd729f45678b027c1f56ea10c7-0-2\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">aux</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M340,184.0 L332,172.0 348,172.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-6eb201bd729f45678b027c1f56ea10c7-0-3\" stroke-width=\"2px\" d=\"M250,182.0 C250,92.0 400.0,92.0 400.0,182.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-6eb201bd729f45678b027c1f56ea10c7-0-3\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">xcomp</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M400.0,184.0 L408.0,172.0 392.0,172.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-6eb201bd729f45678b027c1f56ea10c7-0-4\" stroke-width=\"2px\" d=\"M520,182.0 C520,92.0 670.0,92.0 670.0,182.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-6eb201bd729f45678b027c1f56ea10c7-0-4\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">det</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M520,184.0 L512,172.0 528,172.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-6eb201bd729f45678b027c1f56ea10c7-0-5\" stroke-width=\"2px\" d=\"M610,182.0 C610,137.0 665.0,137.0 665.0,182.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-6eb201bd729f45678b027c1f56ea10c7-0-5\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">compound</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M610,184.0 L602,172.0 618,172.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-6eb201bd729f45678b027c1f56ea10c7-0-6\" stroke-width=\"2px\" d=\"M430,182.0 C430,47.0 675.0,47.0 675.0,182.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-6eb201bd729f45678b027c1f56ea10c7-0-6\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">dobj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M675.0,184.0 L683.0,172.0 667.0,172.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-6eb201bd729f45678b027c1f56ea10c7-0-7\" stroke-width=\"2px\" d=\"M430,182.0 C430,2.0 770.0,2.0 770.0,182.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-6eb201bd729f45678b027c1f56ea10c7-0-7\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">prep</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M770.0,184.0 L778.0,172.0 762.0,172.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-6eb201bd729f45678b027c1f56ea10c7-0-8\" stroke-width=\"2px\" d=\"M880,182.0 C880,92.0 1030.0,92.0 1030.0,182.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-6eb201bd729f45678b027c1f56ea10c7-0-8\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">quantmod</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M880,184.0 L872,172.0 888,172.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-6eb201bd729f45678b027c1f56ea10c7-0-9\" stroke-width=\"2px\" d=\"M970,182.0 C970,137.0 1025.0,137.0 1025.0,182.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-6eb201bd729f45678b027c1f56ea10c7-0-9\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">compound</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M970,184.0 L962,172.0 978,172.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-6eb201bd729f45678b027c1f56ea10c7-0-10\" stroke-width=\"2px\" d=\"M790,182.0 C790,47.0 1035.0,47.0 1035.0,182.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-6eb201bd729f45678b027c1f56ea10c7-0-10\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">pobj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1035.0,184.0 L1043.0,172.0 1027.0,172.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "</svg>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "displacy.render(doc, style='dep', jupyter=True, options={'distance': 90})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the arches of dependecy parser do not appear on the visualization, in a new cell run `displacy.serve(doc, style='dep')` and then open new browser page and type: `http://127.0.0.1:5000/`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lemmatization and stemming\n",
    "\n",
    "`Stemming` is a proces of reducing inflected words to their word stem. Here, \"boat\" would be the stem for [boat, boater, boating, boats]. However, in languages with many exceptions we need more sophisticated methods to perform proper stemming. spaCy does not include a stemmer, inbsted it relies entirely on the lemmatization.\n",
    "<br><br>\n",
    "`Lemmatization` on the other hand applies morphological analysis to the word and considers full vocabulary of the language. As a result, the lemma of `was` is be, `better` is good and so on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(u\"Running was the only thing he could think of while playing with knives\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running      run          VERB     verb, gerund or present participle\n",
      "was          be           AUX      verb, past tense\n",
      "the          the          DET      determiner\n",
      "only         only         ADJ      adjective\n",
      "thing        thing        NOUN     noun, singular or mass\n",
      "he           -PRON-       PRON     pronoun, personal\n",
      "could        could        VERB     verb, modal auxiliary\n",
      "think        think        VERB     verb, base form\n",
      "of           of           ADP      conjunction, subordinating or preposition\n",
      "while        while        SCONJ    conjunction, subordinating or preposition\n",
      "playing      play         VERB     verb, gerund or present participle\n",
      "with         with         ADP      conjunction, subordinating or preposition\n",
      "knives       knife        NOUN     noun, plural\n"
     ]
    }
   ],
   "source": [
    "for token in doc:\n",
    "    print(f'{token.text:{12}} {token.lemma_:{12}} {token.pos_:{8}} {spacy.explain(token.tag_)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stop words\n",
    "\n",
    "Certain words appear so often in language that they do not require tagging. These words are called `stop words` and we usually filter them out from the processed text. spaCy and other NLP libraries contain inbuilt lists of stop words that are ready for usage. NB stop words list can be modified. spaCy contains 326 stopwords."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(nlp.Defaults.stop_words)\n",
    "#len(nlp.Defaults.stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if a word is a stop word\n",
    "nlp.vocab['me'].is_stop\n",
    "\n",
    "# add a stop word\n",
    "nlp.Defaults.stop_words.add('macaroni')\n",
    "\n",
    "# set the stop_word tag on the lexeme\n",
    "nlp.vocab['macaroni'].is_stop = True\n",
    "\n",
    "# remove the word from the list\n",
    "nlp.Defaults.stop_words.remove('macaroni')\n",
    "\n",
    "# remove the stop_word tag from the lexeme\n",
    "nlp.vocab['macaroni'].is_stop = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "References: <br/>\n",
    "1.Wikipedia"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Word embeddings \n",
    "\n",
    "In a nutshell word embeddings or word vectors are numerical representation of text. Embeddings are capable of capturing the context of a word within a document and provide a broader meaning.\n",
    "\n",
    "`You shall know a word by the company it keeps` said by a famous British linguist John Rupert Firth represent this idea, meaning that the words in part determined by its collocations. In that way, if we represent words in a multidimensional space the words similar to each like `car` and `bike` other will have closer values. Cosine similarity is used to calculate the distance between the vectors - and it is a measure how similar the words are (0:1)\n",
    "\n",
    "Mostly used models: Word2Vec (SkipGram and CBOW algorithms) and GloVe.\n",
    "\n",
    "Before feeding the text to any machine learning model we first need to convert text strings into numbers.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Word embeddings with spaCy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We load the large english language model - that was trained on OntoNotes - large corpus comprising various genres \n",
    "# of text (news, conversational telephone speech, weblogs, usenet newsgroups, broadcast, talk shows). \n",
    "# With GloVe vectors trained on CommonCrawl - 685k unique vectors (300 dimensions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(300,)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# acces vector a word\n",
    "nlp('car').vector\n",
    "\n",
    "# shape o a word vector\n",
    "nlp('car').vector.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7667539083302181"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp('car').similarity(nlp('vehicle'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Topic modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download dataset from: https://www.kaggle.com/snap/amazon-fine-food-reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews = pd.read_csv('Reviews.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>ProductId</th>\n",
       "      <th>UserId</th>\n",
       "      <th>ProfileName</th>\n",
       "      <th>HelpfulnessNumerator</th>\n",
       "      <th>HelpfulnessDenominator</th>\n",
       "      <th>Score</th>\n",
       "      <th>Time</th>\n",
       "      <th>Summary</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>568449</th>\n",
       "      <td>568450</td>\n",
       "      <td>B001EO7N10</td>\n",
       "      <td>A28KG5XORO54AY</td>\n",
       "      <td>Lettie D. Carter</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1299628800</td>\n",
       "      <td>Will not do without</td>\n",
       "      <td>Great for sesame chicken..this is a good if no...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568450</th>\n",
       "      <td>568451</td>\n",
       "      <td>B003S1WTCU</td>\n",
       "      <td>A3I8AFVPEE8KI5</td>\n",
       "      <td>R. Sawyer</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1331251200</td>\n",
       "      <td>disappointed</td>\n",
       "      <td>I'm disappointed with the flavor. The chocolat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568451</th>\n",
       "      <td>568452</td>\n",
       "      <td>B004I613EE</td>\n",
       "      <td>A121AA1GQV751Z</td>\n",
       "      <td>pksd \"pk_007\"</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>1329782400</td>\n",
       "      <td>Perfect for our maltipoo</td>\n",
       "      <td>These stars are small, so you can give 10-15 o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568452</th>\n",
       "      <td>568453</td>\n",
       "      <td>B004I613EE</td>\n",
       "      <td>A3IBEVCTXKNOH</td>\n",
       "      <td>Kathy A. Welch \"katwel\"</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1331596800</td>\n",
       "      <td>Favorite Training and reward treat</td>\n",
       "      <td>These are the BEST treats for training and rew...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568453</th>\n",
       "      <td>568454</td>\n",
       "      <td>B001LR2CU2</td>\n",
       "      <td>A3LGQPJCZVL9UC</td>\n",
       "      <td>srfell17</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1338422400</td>\n",
       "      <td>Great Honey</td>\n",
       "      <td>I am very satisfied ,product is as advertised,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Id   ProductId          UserId              ProfileName  \\\n",
       "568449  568450  B001EO7N10  A28KG5XORO54AY         Lettie D. Carter   \n",
       "568450  568451  B003S1WTCU  A3I8AFVPEE8KI5                R. Sawyer   \n",
       "568451  568452  B004I613EE  A121AA1GQV751Z            pksd \"pk_007\"   \n",
       "568452  568453  B004I613EE   A3IBEVCTXKNOH  Kathy A. Welch \"katwel\"   \n",
       "568453  568454  B001LR2CU2  A3LGQPJCZVL9UC                 srfell17   \n",
       "\n",
       "        HelpfulnessNumerator  HelpfulnessDenominator  Score        Time  \\\n",
       "568449                     0                       0      5  1299628800   \n",
       "568450                     0                       0      2  1331251200   \n",
       "568451                     2                       2      5  1329782400   \n",
       "568452                     1                       1      5  1331596800   \n",
       "568453                     0                       0      5  1338422400   \n",
       "\n",
       "                                   Summary  \\\n",
       "568449                 Will not do without   \n",
       "568450                        disappointed   \n",
       "568451            Perfect for our maltipoo   \n",
       "568452  Favorite Training and reward treat   \n",
       "568453                         Great Honey   \n",
       "\n",
       "                                                     Text  \n",
       "568449  Great for sesame chicken..this is a good if no...  \n",
       "568450  I'm disappointed with the flavor. The chocolat...  \n",
       "568451  These stars are small, so you can give 10-15 o...  \n",
       "568452  These are the BEST treats for training and rew...  \n",
       "568453  I am very satisfied ,product is as advertised,...  "
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(568454, 10)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Product arrived labeled as Jumbo Salted Peanuts...the peanuts were actually small sized unsalted. Not sure if this was an error or if the vendor intended to represent the product as \"Jumbo\".'"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews['Text'][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Even with small containers, they don't fill them up.  These little tins are less than half filled and at the price charged it seems a rip-off. Is there some exotic ingredient as costly as gold contained in those tiny squares?  Or how about the cereal ploy, they were filled at the factory but settled in transport.<br />Can manufacturers be honest in their dealings?\""
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews['Text'][200]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(568454, 10)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(568411, 10)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews.dropna(inplace=True)\n",
    "reviews.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a subset of df in order to improve performance\n",
    "#subset = reviews.Text[:10000]\n",
    "subset = reviews.Text[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      I have bought several of the Vitality canned d...\n",
       "1      Product arrived labeled as Jumbo Salted Peanut...\n",
       "2      This is a confection that has been around a fe...\n",
       "3      If you are looking for the secret ingredient i...\n",
       "4      Great taffy at a great price.  There was a wid...\n",
       "5      I got a wild hair for taffy and ordered this f...\n",
       "6      This saltwater taffy had great flavors and was...\n",
       "7      This taffy is so good.  It is very soft and ch...\n",
       "8      Right now I'm mostly just sprouting this so my...\n",
       "9      This is a very healthy dog food. Good for thei...\n",
       "10     I don't know if it's the cactus or the tequila...\n",
       "11     One of my boys needed to lose some weight and ...\n",
       "12     My cats have been happily eating Felidae Plati...\n",
       "13     good flavor! these came securely packed... the...\n",
       "14     The Strawberry Twizzlers are my guilty pleasur...\n",
       "15     My daughter loves twizzlers and this shipment ...\n",
       "16     I love eating them and they are good for watch...\n",
       "17     I am very satisfied with my Twizzler purchase....\n",
       "18     Twizzlers, Strawberry my childhood favorite ca...\n",
       "19     Candy was delivered very fast and was purchase...\n",
       "20     My husband is a Twizzlers addict.  We've bough...\n",
       "21     I bought these for my husband who is currently...\n",
       "22     I can remember buying this candy as a kid and ...\n",
       "23     I love this candy.  After weight watchers I ha...\n",
       "24     I have lived out of the US for over 7 yrs now,...\n",
       "25     Product received is as advertised.<br /><br />...\n",
       "26     The candy is just red , No flavor . Just  plan...\n",
       "27     I was so glad Amazon carried these batteries. ...\n",
       "28     I got this for my Mum who is not diabetic but ...\n",
       "29     I don't know if it's the cactus or the tequila...\n",
       "                             ...                        \n",
       "970    Nothing easier. Nothing better. Even beats gra...\n",
       "971    I have used Pioneer Gravy for a number of year...\n",
       "972    Its great to be able to get sugar this way.Its...\n",
       "973    I am a coffee fanatic but have always stayed a...\n",
       "974    I don't think these coffee bags are as good as...\n",
       "975    I keep Regular bags and Decaf bags in my home ...\n",
       "976    I live in the dorms without a kitchen so makin...\n",
       "977    My primary point with this review is to note t...\n",
       "978    We can't have any kind of coffee maker at work...\n",
       "979    These are great for at work, just pop the inst...\n",
       "980    Fast, easy and definitely delicious.  Makes a ...\n",
       "981    I gave this tea a try to add variety to my tea...\n",
       "982    I tried this before having normal red tea so I...\n",
       "983    I previously tried other matcha products and w...\n",
       "984    This is the very best marinade you can buy as ...\n",
       "985    This is a great product for those looking for ...\n",
       "986    My poland spring driver gave us this new tea t...\n",
       "987    This hot sauce is one of my favorites. Its a p...\n",
       "988    I was never much of a hot sauce fan until I ta...\n",
       "989    This is my favorite hot sauce! I liketo use it...\n",
       "990    They have this in a local diner that I eat in ...\n",
       "991    I was browsing around on Amazon looking for gi...\n",
       "992    This is my favorite hot sauce. I buy it locall...\n",
       "993    So far I have had the habanero and the medium ...\n",
       "994    absolutely love the habenaro sauce...use it on...\n",
       "995    BLACK MARKET HOT SAUCE IS WONDERFUL.... My hus...\n",
       "996    Man what can i say, this salsa is the bomb!! i...\n",
       "997    this sauce is so good with just about anything...\n",
       "998    Not hot at all. Like the other low star review...\n",
       "999    I have to admit, I was a sucker for the large ...\n",
       "Name: Text, Length: 1000, dtype: object"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removing stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy.lemmatizer import Lemmatizer\n",
    "from spacy.lang.en.stop_words import STOP_WORDS\n",
    "from spacy.lang.en import English\n",
    "import re\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from collections import defaultdict "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cleaning function for removing stopwords and creating lemma\n",
    "def cleaning(doc):\n",
    "    txt = [token.lemma_ for token in doc if not token.is_stop]\n",
    "    return txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Even with small containers, they don't fill them up.  These little tins are less than half filled and at the price charged it seems a rip-off. Is there some exotic ingredient as costly as gold contained in those tiny squares?  Or how about the cereal ploy, they were filled at the factory but settled in transport.<br />Can manufacturers be honest in their dealings?\""
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# example of a 'dirty' review before processing\n",
    "subset[200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lowercase the words and remove all html tags and store the results in remove_html_tags\n",
    "remove_html_tags = [re.sub(re.compile('<.*?>'), '', str(row)).lower() for row in subset]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"even with small containers, they don't fill them up.  these little tins are less than half filled and at the price charged it seems a rip-off. is there some exotic ingredient as costly as gold contained in those tiny squares?  or how about the cereal ploy, they were filled at the factory but settled in transport.can manufacturers be honest in their dealings?\""
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print results after removing html tags\n",
    "remove_html_tags[200]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Results you should receive: <br>\n",
    "`\"even with small containers, they don't fill them up.  these little tins are less than half filled and at the price charged it seems a rip-off. is there some exotic ingredient as costly as gold contained in those tiny squares?  or how about the cereal ploy, they were filled at the factory but settled in transport.can manufacturers be honest in their dealings?\"`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove all non-alphabetic characters and store in remove_non_alpha\n",
    "remove_non_alpha = [re.sub(\"[^A-Za-z']+\", ' ', row) for row in remove_html_tags]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"even with small containers they don't fill them up these little tins are less than half filled and at the price charged it seems a rip off is there some exotic ingredient as costly as gold contained in those tiny squares or how about the cereal ploy they were filled at the factory but settled in transport can manufacturers be honest in their dealings \""
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print the results after removing non-alphabetic characters\n",
    "remove_non_alpha[200]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Results you should get: <br>\n",
    "`\"even with small containers they don't fill them up these little tins are less than half filled and at the price charged it seems a rip off is there some exotic ingredient as costly as gold contained in those tiny squares or how about the cereal ploy they were filled at the factory but settled in transport can manufacturers be honest in their dealings \"`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply the cleaning function to the\n",
    "txt = [cleaning(doc) for doc in nlp.pipe(remove_non_alpha, batch_size = 1000, n_threads = -1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['small', 'container', 'fill', 'little', 'tin', 'half', 'fill', 'price', 'charge', 'rip', 'exotic', 'ingredient', 'costly', 'gold', 'contain', 'tiny', 'square', 'cereal', 'ploy', 'fill', 'factory', 'settle', 'transport', 'manufacturer', 'honest', 'dealing']\n"
     ]
    }
   ],
   "source": [
    "print(txt[200])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Even with small containers, they don't fill them up.  These little tins are less than half filled and at the price charged it seems a rip-off. Is there some exotic ingredient as costly as gold contained in those tiny squares?  Or how about the cereal ploy, they were filled at the factory but settled in transport.<br />Can manufacturers be honest in their dealings?\""
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews['Text'][200]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Install gensim via anaconda `conda install -c conda-forge gensim`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import gensim\n",
    "import gensim.corpora as corpora\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.models import CoherenceModel\n",
    "from gensim.models.ldamodel import LdaModel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For full documentation go to: <br> `https://radimrehurek.com/gensim/models/ldamodel.html`<br> `https://radimrehurek.com/gensim/corpora/dictionary.html`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates a dictionary, which is a mapping of word IDs to words.\n",
    "id2word = corpora.Dictionary(txt)\n",
    "\n",
    "# Turns each document into a bag of words - containing how many times each word (word id) occured within a document\n",
    "corpus = [id2word.doc2bow(doc) for doc in txt]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "actually\n"
     ]
    }
   ],
   "source": [
    "print(id2word[19])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(14, 2), (19, 1), (20, 1), (21, 1), (22, 1), (23, 2), (24, 1), (25, 2), (26, 1), (27, 1), (28, 1), (29, 1), (30, 1), (31, 1), (32, 1)]\n"
     ]
    }
   ],
   "source": [
    "print(corpus[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bag of words : occurences or a word within a document. BoW disregards all informatio about the word meaning or word order. It simply counts how many occurences of a word is there in each document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_model = gensim.models.ldamodel.LdaModel(corpus=corpus,\n",
    "                                           id2word=id2word,\n",
    "                                           num_topics=5, \n",
    "                                           random_state=42,\n",
    "                                           #update_every=1,\n",
    "                                           #passes=10,\n",
    "                                           alpha=.1, #distribution of the number of topics per document\n",
    "                                           chunksize=100,\n",
    "                                           per_word_topics=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0,\n",
      "  '0.015*\"son\" + 0.015*\"great\" + 0.013*\"good\" + 0.012*\"find\" + 0.012*\"love\" + '\n",
      "  '0.010*\"dinner\" + 0.010*\"plastic\" + 0.009*\"use\" + 0.009*\"look\" + '\n",
      "  '0.008*\"taste\"'),\n",
      " (1,\n",
      "  '0.026*\"good\" + 0.019*\"baby\" + 0.015*\"product\" + 0.014*\"organic\" + '\n",
      "  '0.014*\"food\" + 0.013*\"love\" + 0.013*\"try\" + 0.013*\"bag\" + 0.012*\"great\" + '\n",
      "  '0.012*\"price\"'),\n",
      " (2,\n",
      "  '0.076*\"chip\" + 0.023*\"taste\" + 0.018*\"like\" + 0.018*\"salt\" + 0.017*\"flavor\" '\n",
      "  '+ 0.015*\"bar\" + 0.015*\"product\" + 0.013*\"kettle\" + 0.010*\"try\" + '\n",
      "  '0.009*\"brand\"'),\n",
      " (3,\n",
      "  '0.024*\"tea\" + 0.018*\"bag\" + 0.017*\"like\" + 0.015*\"coffee\" + 0.013*\"taste\" + '\n",
      "  '0.012*\"order\" + 0.012*\"chocolate\" + 0.011*\"flavor\" + 0.010*\"buy\" + '\n",
      "  '0.008*\"time\"'),\n",
      " (4,\n",
      "  '0.022*\"good\" + 0.020*\"like\" + 0.020*\"flavor\" + 0.020*\"food\" + 0.015*\"sauce\" '\n",
      "  '+ 0.012*\"hot\" + 0.011*\"potato\" + 0.011*\"chip\" + 0.011*\"rice\" + '\n",
      "  '0.010*\"spicy\"')]\n"
     ]
    }
   ],
   "source": [
    "pprint(lda_model.print_topics(num_words=10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/majakiszka/anaconda3/lib/python3.7/site-packages/scipy/sparse/lil.py:504: FutureWarning: future versions will not create a writeable array from broadcast_array. Set the writable flag explicitly to avoid this warning.\n",
      "  if not i.flags.writeable or i.dtype not in (np.int32, np.int64):\n",
      "/Users/majakiszka/anaconda3/lib/python3.7/site-packages/scipy/sparse/lil.py:506: FutureWarning: future versions will not create a writeable array from broadcast_array. Set the writable flag explicitly to avoid this warning.\n",
      "  if not j.flags.writeable or j.dtype not in (np.int32, np.int64):\n",
      "/Users/majakiszka/anaconda3/lib/python3.7/site-packages/scipy/sparse/lil.py:320: DeprecationWarning: Numpy has detected that you (may be) writing to an array with\n",
      "overlapping memory from np.broadcast_arrays. If this is intentional\n",
      "set the WRITEABLE flag True or make a copy immediately before writing.\n",
      "  i, j, x)\n",
      "/Users/majakiszka/anaconda3/lib/python3.7/site-packages/scipy/sparse/lil.py:320: DeprecationWarning: Numpy has detected that you (may be) writing to an array with\n",
      "overlapping memory from np.broadcast_arrays. If this is intentional\n",
      "set the WRITEABLE flag True or make a copy immediately before writing.\n",
      "  i, j, x)\n",
      "/Users/majakiszka/anaconda3/lib/python3.7/site-packages/scipy/sparse/lil.py:320: DeprecationWarning: Numpy has detected that you (may be) writing to an array with\n",
      "overlapping memory from np.broadcast_arrays. If this is intentional\n",
      "set the WRITEABLE flag True or make a copy immediately before writing.\n",
      "  i, j, x)\n",
      "/Users/majakiszka/anaconda3/lib/python3.7/site-packages/scipy/sparse/lil.py:320: DeprecationWarning: Numpy has detected that you (may be) writing to an array with\n",
      "overlapping memory from np.broadcast_arrays. If this is intentional\n",
      "set the WRITEABLE flag True or make a copy immediately before writing.\n",
      "  i, j, x)\n",
      "/Users/majakiszka/anaconda3/lib/python3.7/site-packages/scipy/sparse/lil.py:320: DeprecationWarning: Numpy has detected that you (may be) writing to an array with\n",
      "overlapping memory from np.broadcast_arrays. If this is intentional\n",
      "set the WRITEABLE flag True or make a copy immediately before writing.\n",
      "  i, j, x)\n",
      "/Users/majakiszka/anaconda3/lib/python3.7/site-packages/scipy/sparse/lil.py:320: DeprecationWarning: Numpy has detected that you (may be) writing to an array with\n",
      "overlapping memory from np.broadcast_arrays. If this is intentional\n",
      "set the WRITEABLE flag True or make a copy immediately before writing.\n",
      "  i, j, x)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Coherence Score:  0.27253753198717245\n"
     ]
    }
   ],
   "source": [
    "# Coherence score give an approximation of how good the topics are, it determines the optimal number of topics.\n",
    "# So, the higher the score the better : 0 < x < 1\n",
    "\n",
    "\n",
    "# Compute Coherence Score\n",
    "coherence_model_lda = CoherenceModel(model=lda_model, texts=txt, dictionary=id2word, coherence='c_v')\n",
    "coherence_lda = coherence_model_lda.get_coherence()\n",
    "print('\\nCoherence Score: ', coherence_lda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# source: https://datascienceplus.com/evaluation-of-topic-modeling-topic-coherence/\n",
    "def compute_coherence_values(dictionary, corpus, texts, limit, start=2, step=3):\n",
    "    \"\"\"\n",
    "    Compute c_v coherence for various number of topics\n",
    "\n",
    "    Parameters:\n",
    "    ----------\n",
    "    dictionary : Gensim dictionary\n",
    "    corpus : Gensim corpus\n",
    "    texts : List of input texts\n",
    "    limit : Max num of topics\n",
    "\n",
    "    Returns:\n",
    "    -------\n",
    "    model_list : List of LDA topic models\n",
    "    coherence_values : Coherence values corresponding to the LDA model with respective number of topics\n",
    "    \"\"\"\n",
    "    coherence_values = []\n",
    "    model_list = []\n",
    "    for num_topics in range(start, limit, step):\n",
    "        model=LdaModel(corpus=corpus, id2word=dictionary, num_topics=num_topics)\n",
    "        model_list.append(model)\n",
    "        coherencemodel = CoherenceModel(model=model, texts=texts, dictionary=dictionary, coherence='c_v')\n",
    "        coherence_values.append(coherencemodel.get_coherence())\n",
    "\n",
    "    return model_list, coherence_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/majakiszka/anaconda3/lib/python3.7/site-packages/scipy/sparse/lil.py:320: DeprecationWarning: Numpy has detected that you (may be) writing to an array with\n",
      "overlapping memory from np.broadcast_arrays. If this is intentional\n",
      "set the WRITEABLE flag True or make a copy immediately before writing.\n",
      "  i, j, x)\n",
      "/Users/majakiszka/anaconda3/lib/python3.7/site-packages/scipy/sparse/lil.py:320: DeprecationWarning: Numpy has detected that you (may be) writing to an array with\n",
      "overlapping memory from np.broadcast_arrays. If this is intentional\n",
      "set the WRITEABLE flag True or make a copy immediately before writing.\n",
      "  i, j, x)\n",
      "/Users/majakiszka/anaconda3/lib/python3.7/site-packages/scipy/sparse/lil.py:320: DeprecationWarning: Numpy has detected that you (may be) writing to an array with\n",
      "overlapping memory from np.broadcast_arrays. If this is intentional\n",
      "set the WRITEABLE flag True or make a copy immediately before writing.\n",
      "  i, j, x)\n",
      "/Users/majakiszka/anaconda3/lib/python3.7/site-packages/scipy/sparse/lil.py:320: DeprecationWarning: Numpy has detected that you (may be) writing to an array with\n",
      "overlapping memory from np.broadcast_arrays. If this is intentional\n",
      "set the WRITEABLE flag True or make a copy immediately before writing.\n",
      "  i, j, x)\n",
      "/Users/majakiszka/anaconda3/lib/python3.7/site-packages/scipy/sparse/lil.py:320: DeprecationWarning: Numpy has detected that you (may be) writing to an array with\n",
      "overlapping memory from np.broadcast_arrays. If this is intentional\n",
      "set the WRITEABLE flag True or make a copy immediately before writing.\n",
      "  i, j, x)\n",
      "/Users/majakiszka/anaconda3/lib/python3.7/site-packages/scipy/sparse/lil.py:320: DeprecationWarning: Numpy has detected that you (may be) writing to an array with\n",
      "overlapping memory from np.broadcast_arrays. If this is intentional\n",
      "set the WRITEABLE flag True or make a copy immediately before writing.\n",
      "  i, j, x)\n",
      "/Users/majakiszka/anaconda3/lib/python3.7/site-packages/scipy/sparse/lil.py:320: DeprecationWarning: Numpy has detected that you (may be) writing to an array with\n",
      "overlapping memory from np.broadcast_arrays. If this is intentional\n",
      "set the WRITEABLE flag True or make a copy immediately before writing.\n",
      "  i, j, x)\n",
      "/Users/majakiszka/anaconda3/lib/python3.7/site-packages/scipy/sparse/lil.py:320: DeprecationWarning: Numpy has detected that you (may be) writing to an array with\n",
      "overlapping memory from np.broadcast_arrays. If this is intentional\n",
      "set the WRITEABLE flag True or make a copy immediately before writing.\n",
      "  i, j, x)\n",
      "/Users/majakiszka/anaconda3/lib/python3.7/site-packages/scipy/sparse/lil.py:320: DeprecationWarning: Numpy has detected that you (may be) writing to an array with\n",
      "overlapping memory from np.broadcast_arrays. If this is intentional\n",
      "set the WRITEABLE flag True or make a copy immediately before writing.\n",
      "  i, j, x)\n",
      "/Users/majakiszka/anaconda3/lib/python3.7/site-packages/scipy/sparse/lil.py:320: DeprecationWarning: Numpy has detected that you (may be) writing to an array with\n",
      "overlapping memory from np.broadcast_arrays. If this is intentional\n",
      "set the WRITEABLE flag True or make a copy immediately before writing.\n",
      "  i, j, x)\n",
      "/Users/majakiszka/anaconda3/lib/python3.7/site-packages/scipy/sparse/lil.py:320: DeprecationWarning: Numpy has detected that you (may be) writing to an array with\n",
      "overlapping memory from np.broadcast_arrays. If this is intentional\n",
      "set the WRITEABLE flag True or make a copy immediately before writing.\n",
      "  i, j, x)\n",
      "/Users/majakiszka/anaconda3/lib/python3.7/site-packages/scipy/sparse/lil.py:320: DeprecationWarning: Numpy has detected that you (may be) writing to an array with\n",
      "overlapping memory from np.broadcast_arrays. If this is intentional\n",
      "set the WRITEABLE flag True or make a copy immediately before writing.\n",
      "  i, j, x)\n",
      "/Users/majakiszka/anaconda3/lib/python3.7/site-packages/scipy/sparse/lil.py:320: DeprecationWarning: Numpy has detected that you (may be) writing to an array with\n",
      "overlapping memory from np.broadcast_arrays. If this is intentional\n",
      "set the WRITEABLE flag True or make a copy immediately before writing.\n",
      "  i, j, x)\n",
      "/Users/majakiszka/anaconda3/lib/python3.7/site-packages/scipy/sparse/lil.py:320: DeprecationWarning: Numpy has detected that you (may be) writing to an array with\n",
      "overlapping memory from np.broadcast_arrays. If this is intentional\n",
      "set the WRITEABLE flag True or make a copy immediately before writing.\n",
      "  i, j, x)\n",
      "/Users/majakiszka/anaconda3/lib/python3.7/site-packages/scipy/sparse/lil.py:320: DeprecationWarning: Numpy has detected that you (may be) writing to an array with\n",
      "overlapping memory from np.broadcast_arrays. If this is intentional\n",
      "set the WRITEABLE flag True or make a copy immediately before writing.\n",
      "  i, j, x)\n",
      "/Users/majakiszka/anaconda3/lib/python3.7/site-packages/scipy/sparse/lil.py:320: DeprecationWarning: Numpy has detected that you (may be) writing to an array with\n",
      "overlapping memory from np.broadcast_arrays. If this is intentional\n",
      "set the WRITEABLE flag True or make a copy immediately before writing.\n",
      "  i, j, x)\n",
      "/Users/majakiszka/anaconda3/lib/python3.7/site-packages/scipy/sparse/lil.py:320: DeprecationWarning: Numpy has detected that you (may be) writing to an array with\n",
      "overlapping memory from np.broadcast_arrays. If this is intentional\n",
      "set the WRITEABLE flag True or make a copy immediately before writing.\n",
      "  i, j, x)\n",
      "/Users/majakiszka/anaconda3/lib/python3.7/site-packages/scipy/sparse/lil.py:320: DeprecationWarning: Numpy has detected that you (may be) writing to an array with\n",
      "overlapping memory from np.broadcast_arrays. If this is intentional\n",
      "set the WRITEABLE flag True or make a copy immediately before writing.\n",
      "  i, j, x)\n",
      "/Users/majakiszka/anaconda3/lib/python3.7/site-packages/scipy/sparse/lil.py:320: DeprecationWarning: Numpy has detected that you (may be) writing to an array with\n",
      "overlapping memory from np.broadcast_arrays. If this is intentional\n",
      "set the WRITEABLE flag True or make a copy immediately before writing.\n",
      "  i, j, x)\n",
      "/Users/majakiszka/anaconda3/lib/python3.7/site-packages/scipy/sparse/lil.py:320: DeprecationWarning: Numpy has detected that you (may be) writing to an array with\n",
      "overlapping memory from np.broadcast_arrays. If this is intentional\n",
      "set the WRITEABLE flag True or make a copy immediately before writing.\n",
      "  i, j, x)\n",
      "/Users/majakiszka/anaconda3/lib/python3.7/site-packages/scipy/sparse/lil.py:320: DeprecationWarning: Numpy has detected that you (may be) writing to an array with\n",
      "overlapping memory from np.broadcast_arrays. If this is intentional\n",
      "set the WRITEABLE flag True or make a copy immediately before writing.\n",
      "  i, j, x)\n",
      "/Users/majakiszka/anaconda3/lib/python3.7/site-packages/scipy/sparse/lil.py:320: DeprecationWarning: Numpy has detected that you (may be) writing to an array with\n",
      "overlapping memory from np.broadcast_arrays. If this is intentional\n",
      "set the WRITEABLE flag True or make a copy immediately before writing.\n",
      "  i, j, x)\n",
      "/Users/majakiszka/anaconda3/lib/python3.7/site-packages/scipy/sparse/lil.py:320: DeprecationWarning: Numpy has detected that you (may be) writing to an array with\n",
      "overlapping memory from np.broadcast_arrays. If this is intentional\n",
      "set the WRITEABLE flag True or make a copy immediately before writing.\n",
      "  i, j, x)\n",
      "/Users/majakiszka/anaconda3/lib/python3.7/site-packages/scipy/sparse/lil.py:320: DeprecationWarning: Numpy has detected that you (may be) writing to an array with\n",
      "overlapping memory from np.broadcast_arrays. If this is intentional\n",
      "set the WRITEABLE flag True or make a copy immediately before writing.\n",
      "  i, j, x)\n",
      "/Users/majakiszka/anaconda3/lib/python3.7/site-packages/scipy/sparse/lil.py:320: DeprecationWarning: Numpy has detected that you (may be) writing to an array with\n",
      "overlapping memory from np.broadcast_arrays. If this is intentional\n",
      "set the WRITEABLE flag True or make a copy immediately before writing.\n",
      "  i, j, x)\n",
      "/Users/majakiszka/anaconda3/lib/python3.7/site-packages/scipy/sparse/lil.py:320: DeprecationWarning: Numpy has detected that you (may be) writing to an array with\n",
      "overlapping memory from np.broadcast_arrays. If this is intentional\n",
      "set the WRITEABLE flag True or make a copy immediately before writing.\n",
      "  i, j, x)\n",
      "/Users/majakiszka/anaconda3/lib/python3.7/site-packages/scipy/sparse/lil.py:320: DeprecationWarning: Numpy has detected that you (may be) writing to an array with\n",
      "overlapping memory from np.broadcast_arrays. If this is intentional\n",
      "set the WRITEABLE flag True or make a copy immediately before writing.\n",
      "  i, j, x)\n",
      "/Users/majakiszka/anaconda3/lib/python3.7/site-packages/scipy/sparse/lil.py:320: DeprecationWarning: Numpy has detected that you (may be) writing to an array with\n",
      "overlapping memory from np.broadcast_arrays. If this is intentional\n",
      "set the WRITEABLE flag True or make a copy immediately before writing.\n",
      "  i, j, x)\n",
      "/Users/majakiszka/anaconda3/lib/python3.7/site-packages/scipy/sparse/lil.py:320: DeprecationWarning: Numpy has detected that you (may be) writing to an array with\n",
      "overlapping memory from np.broadcast_arrays. If this is intentional\n",
      "set the WRITEABLE flag True or make a copy immediately before writing.\n",
      "  i, j, x)\n",
      "/Users/majakiszka/anaconda3/lib/python3.7/site-packages/scipy/sparse/lil.py:320: DeprecationWarning: Numpy has detected that you (may be) writing to an array with\n",
      "overlapping memory from np.broadcast_arrays. If this is intentional\n",
      "set the WRITEABLE flag True or make a copy immediately before writing.\n",
      "  i, j, x)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/majakiszka/anaconda3/lib/python3.7/site-packages/scipy/sparse/lil.py:320: DeprecationWarning: Numpy has detected that you (may be) writing to an array with\n",
      "overlapping memory from np.broadcast_arrays. If this is intentional\n",
      "set the WRITEABLE flag True or make a copy immediately before writing.\n",
      "  i, j, x)\n",
      "/Users/majakiszka/anaconda3/lib/python3.7/site-packages/scipy/sparse/lil.py:320: DeprecationWarning: Numpy has detected that you (may be) writing to an array with\n",
      "overlapping memory from np.broadcast_arrays. If this is intentional\n",
      "set the WRITEABLE flag True or make a copy immediately before writing.\n",
      "  i, j, x)\n",
      "/Users/majakiszka/anaconda3/lib/python3.7/site-packages/scipy/sparse/lil.py:320: DeprecationWarning: Numpy has detected that you (may be) writing to an array with\n",
      "overlapping memory from np.broadcast_arrays. If this is intentional\n",
      "set the WRITEABLE flag True or make a copy immediately before writing.\n",
      "  i, j, x)\n",
      "/Users/majakiszka/anaconda3/lib/python3.7/site-packages/scipy/sparse/lil.py:320: DeprecationWarning: Numpy has detected that you (may be) writing to an array with\n",
      "overlapping memory from np.broadcast_arrays. If this is intentional\n",
      "set the WRITEABLE flag True or make a copy immediately before writing.\n",
      "  i, j, x)\n",
      "/Users/majakiszka/anaconda3/lib/python3.7/site-packages/scipy/sparse/lil.py:320: DeprecationWarning: Numpy has detected that you (may be) writing to an array with\n",
      "overlapping memory from np.broadcast_arrays. If this is intentional\n",
      "set the WRITEABLE flag True or make a copy immediately before writing.\n",
      "  i, j, x)\n",
      "/Users/majakiszka/anaconda3/lib/python3.7/site-packages/scipy/sparse/lil.py:320: DeprecationWarning: Numpy has detected that you (may be) writing to an array with\n",
      "overlapping memory from np.broadcast_arrays. If this is intentional\n",
      "set the WRITEABLE flag True or make a copy immediately before writing.\n",
      "  i, j, x)\n",
      "/Users/majakiszka/anaconda3/lib/python3.7/site-packages/scipy/sparse/lil.py:320: DeprecationWarning: Numpy has detected that you (may be) writing to an array with\n",
      "overlapping memory from np.broadcast_arrays. If this is intentional\n",
      "set the WRITEABLE flag True or make a copy immediately before writing.\n",
      "  i, j, x)\n",
      "/Users/majakiszka/anaconda3/lib/python3.7/site-packages/scipy/sparse/lil.py:320: DeprecationWarning: Numpy has detected that you (may be) writing to an array with\n",
      "overlapping memory from np.broadcast_arrays. If this is intentional\n",
      "set the WRITEABLE flag True or make a copy immediately before writing.\n",
      "  i, j, x)\n",
      "/Users/majakiszka/anaconda3/lib/python3.7/site-packages/scipy/sparse/lil.py:320: DeprecationWarning: Numpy has detected that you (may be) writing to an array with\n",
      "overlapping memory from np.broadcast_arrays. If this is intentional\n",
      "set the WRITEABLE flag True or make a copy immediately before writing.\n",
      "  i, j, x)\n",
      "/Users/majakiszka/anaconda3/lib/python3.7/site-packages/scipy/sparse/lil.py:320: DeprecationWarning: Numpy has detected that you (may be) writing to an array with\n",
      "overlapping memory from np.broadcast_arrays. If this is intentional\n",
      "set the WRITEABLE flag True or make a copy immediately before writing.\n",
      "  i, j, x)\n",
      "/Users/majakiszka/anaconda3/lib/python3.7/site-packages/scipy/sparse/lil.py:320: DeprecationWarning: Numpy has detected that you (may be) writing to an array with\n",
      "overlapping memory from np.broadcast_arrays. If this is intentional\n",
      "set the WRITEABLE flag True or make a copy immediately before writing.\n",
      "  i, j, x)\n",
      "/Users/majakiszka/anaconda3/lib/python3.7/site-packages/scipy/sparse/lil.py:320: DeprecationWarning: Numpy has detected that you (may be) writing to an array with\n",
      "overlapping memory from np.broadcast_arrays. If this is intentional\n",
      "set the WRITEABLE flag True or make a copy immediately before writing.\n",
      "  i, j, x)\n"
     ]
    }
   ],
   "source": [
    "# source https://datascienceplus.com/evaluation-of-topic-modeling-topic-coherence/\n",
    "model_list, coherence_values = compute_coherence_values(dictionary=id2word, corpus=corpus, texts=txt, start=2, limit=40, step=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Show graph\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "limit=40; start=2; step=6;\n",
    "x = range(start, limit, step)\n",
    "plt.plot(x, coherence_values)\n",
    "plt.xlabel(\"Num Topics\")\n",
    "plt.ylabel(\"Coherence score\")\n",
    "plt.legend((\"coherence_values\"), loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# conda install -c conda-forge pyldavis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyLDAvis import gensim as pyLDAvis_gensim\n",
    "import pickle \n",
    "import pyLDAvis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The visualization below, will allow you to compare topics and see what is the distribution of words per topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.87 s, sys: 868 ms, total: 4.74 s\n",
      "Wall time: 2min 58s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/majakiszka/anaconda3/lib/python3.7/site-packages/pyLDAvis/_prepare.py:257: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  return pd.concat([default_term_info] + list(topic_dfs))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<link rel=\"stylesheet\" type=\"text/css\" href=\"https://cdn.rawgit.com/bmabey/pyLDAvis/files/ldavis.v1.0.0.css\">\n",
       "\n",
       "\n",
       "<div id=\"ldavis_el74344756527602275292864\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "\n",
       "var ldavis_el74344756527602275292864_data = {\"mdsDat\": {\"x\": [0.05378742720826231, 0.06433716622284455, -0.021642584767247373, -0.18103666565511212, 0.08455465699125271], \"y\": [0.03335959962256324, -0.07900654883953588, -0.1167938885935722, 0.04884994132475137, 0.11359089648579349], \"topics\": [1, 2, 3, 4, 5], \"cluster\": [1, 1, 1, 1, 1], \"Freq\": [27.688396453857422, 21.139148712158203, 19.3714656829834, 17.334280014038086, 14.466714859008789]}, \"tinfo\": {\"Category\": [\"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\"], \"Freq\": [503.0, 222.0, 128.0, 101.0, 84.0, 91.0, 67.0, 136.0, 124.0, 263.0, 150.0, 267.0, 87.0, 67.0, 60.0, 57.0, 45.0, 74.0, 244.0, 344.0, 465.0, 48.0, 67.0, 241.0, 131.0, 137.0, 42.0, 130.0, 82.0, 51.0, 41.45771026611328, 35.773651123046875, 32.10282516479492, 31.014129638671875, 32.19179153442383, 25.906770706176758, 25.934303283691406, 23.92624855041504, 24.422452926635742, 19.01955223083496, 26.742130279541016, 17.01949119567871, 16.640377044677734, 15.98187255859375, 31.220670700073242, 15.478109359741211, 15.389077186584473, 13.539405822753906, 13.058347702026367, 14.24971866607666, 21.067401885986328, 14.096774101257324, 18.864852905273438, 11.889117240905762, 11.884403228759766, 27.953676223754883, 10.584720611572266, 9.936229705810547, 35.134822845458984, 9.826508522033691, 206.61624145507812, 48.80670928955078, 44.156333923339844, 130.1654510498047, 34.84298324584961, 103.67655944824219, 33.621952056884766, 66.68666076660156, 29.57703399658203, 106.72290802001953, 33.88444900512695, 44.51286315917969, 158.53427124023438, 33.04832458496094, 45.50791931152344, 42.47117614746094, 63.78628158569336, 149.14297485351562, 48.9263801574707, 87.82624816894531, 110.78430938720703, 68.13904571533203, 38.10128402709961, 95.5861587524414, 55.172889709472656, 44.593780517578125, 63.09735107421875, 45.92334747314453, 63.59584426879883, 48.83089828491211, 39.928585052490234, 45.68185043334961, 43.166168212890625, 38.678382873535156, 39.17613983154297, 127.32106018066406, 40.180030822753906, 36.56025695800781, 31.961210250854492, 30.42295265197754, 21.141027450561523, 17.97856330871582, 17.37889862060547, 16.03044891357422, 15.126265525817871, 16.58489418029785, 13.383100509643555, 21.750621795654297, 10.832772254943848, 10.73485279083252, 12.7959623336792, 16.532665252685547, 9.523269653320312, 9.403820037841797, 47.5663948059082, 8.730316162109375, 11.473207473754883, 16.63425064086914, 8.561078071594238, 67.1929931640625, 6.9792304039001465, 7.566401481628418, 14.088034629821777, 7.552999973297119, 8.53161334991455, 58.70832443237305, 16.53545379638672, 13.784234046936035, 95.47386932373047, 57.90654373168945, 27.879274368286133, 20.59398651123047, 77.98674011230469, 29.601043701171875, 172.72885131835938, 53.19350814819336, 102.34500122070312, 66.42010498046875, 88.13768005371094, 93.92476654052734, 33.97734069824219, 83.21189880371094, 87.51287841796875, 89.26991271972656, 31.36680793762207, 70.0102767944336, 30.852645874023438, 67.23702239990234, 43.69538116455078, 38.46021270751953, 34.9012565612793, 33.92646408081055, 53.062774658203125, 45.03288269042969, 50.46860122680664, 36.30949401855469, 33.50045394897461, 59.946876525878906, 56.6628532409668, 89.96096801757812, 27.38728904724121, 20.17044448852539, 19.15296173095703, 64.52766418457031, 25.480648040771484, 15.826821327209473, 15.860000610351562, 40.862762451171875, 13.12999439239502, 10.925824165344238, 9.457343101501465, 9.805838584899902, 20.056455612182617, 8.809231758117676, 9.30405330657959, 8.460981369018555, 8.136568069458008, 9.281765937805176, 8.04642105102539, 6.390997886657715, 6.750101089477539, 8.102163314819336, 6.009774684906006, 5.863930702209473, 11.765876770019531, 5.7329840660095215, 6.203862190246582, 30.508947372436523, 75.52208709716797, 14.997482299804688, 30.02539825439453, 22.48118019104004, 35.443668365478516, 15.075790405273438, 23.424463272094727, 15.351984024047852, 16.864702224731445, 119.6135482788086, 68.8311767578125, 53.215789794921875, 22.109268188476562, 120.09158325195312, 137.0665283203125, 33.006591796875, 122.43907928466797, 47.54395294189453, 27.6711483001709, 38.3577766418457, 42.08060073852539, 57.17835998535156, 34.82675552368164, 64.94732666015625, 48.618370056152344, 35.74623107910156, 26.899333953857422, 34.63831329345703, 40.51498031616211, 32.72215270996094, 29.170299530029297, 30.075162887573242, 83.28131103515625, 98.32437133789062, 21.93354034423828, 19.070024490356445, 21.909954071044922, 17.169414520263672, 33.43580627441406, 29.48482894897461, 11.527434349060059, 18.73019027709961, 15.508304595947266, 12.875714302062988, 10.954404830932617, 10.6801176071167, 11.584198951721191, 7.903391361236572, 7.6787638664245605, 10.739567756652832, 8.275559425354004, 6.9787468910217285, 32.00440979003906, 8.391082763671875, 10.18288516998291, 7.758828639984131, 8.834295272827148, 9.02424430847168, 11.988809585571289, 21.044496536254883, 14.723344802856445, 6.192409992218018, 417.3324279785156, 13.124439239501953, 35.59614944458008, 42.07720947265625, 16.667612075805664, 12.12795352935791, 71.34168243408203, 30.027048110961914, 23.528230667114258, 123.88334655761719, 33.28619384765625, 80.52875518798828, 92.8530044555664, 51.353363037109375, 101.12223815917969, 53.77505874633789, 20.45354461669922, 27.298677444458008, 20.289525985717773, 23.748699188232422, 40.16558074951172, 38.70207214355469, 36.812103271484375, 31.731149673461914, 33.02445983886719, 23.318334579467773, 25.135684967041016, 21.152896881103516, 67.2015380859375, 44.65055847167969, 31.56706428527832, 23.576496124267578, 12.680967330932617, 10.163013458251953, 23.31624984741211, 11.614338874816895, 10.295417785644531, 22.10213279724121, 9.008495330810547, 8.95756721496582, 8.776659965515137, 12.542755126953125, 13.343520164489746, 6.816223621368408, 43.76484298706055, 9.698092460632324, 7.372005462646484, 9.698177337646484, 5.921994209289551, 11.790410995483398, 8.729752540588379, 9.443778038024902, 6.167229652404785, 37.40214920043945, 5.50536584854126, 5.284799575805664, 5.151943683624268, 5.12938117980957, 8.479948997497559, 8.109686851501465, 17.1387939453125, 16.11622428894043, 20.79538345336914, 19.075380325317383, 14.34727668762207, 11.067007064819336, 11.527510643005371, 31.062698364257812, 32.21208953857422, 38.07643127441406, 66.787353515625, 40.56355667114258, 55.21075439453125, 42.73488235473633, 21.474124908447266, 53.46237564086914, 21.714033126831055, 58.76136779785156, 32.139041900634766, 34.52800750732422, 22.14328384399414, 38.255130767822266, 29.503116607666016, 18.999784469604492, 19.15514373779297, 28.002443313598633, 21.762649536132812], \"Term\": [\"chip\", \"tea\", \"baby\", \"salt\", \"bar\", \"sauce\", \"son\", \"potato\", \"organic\", \"bag\", \"coffee\", \"food\", \"hot\", \"rice\", \"spicy\", \"far\", \"dinner\", \"old\", \"product\", \"flavor\", \"good\", \"plastic\", \"quality\", \"great\", \"kettle\", \"price\", \"take\", \"chocolate\", \"enjoy\", \"stick\", \"packaging\", \"piece\", \"melt\", \"red\", \"chicken\", \"break\", \"absolutely\", \"smooth\", \"berry\", \"leave\", \"online\", \"msg\", \"waste\", \"reviewer\", \"honey\", \"bitter\", \"last\", \"send\", \"agree\", \"seller\", \"husband\", \"addition\", \"course\", \"cherry\", \"addict\", \"black\", \"extract\", \"ice\", \"item\", \"summer\", \"tea\", \"open\", \"protein\", \"coffee\", \"ship\", \"chocolate\", \"definitely\", \"enjoy\", \"green\", \"order\", \"bean\", \"delicious\", \"bag\", \"large\", \"texture\", \"cup\", \"amazon\", \"like\", \"purchase\", \"buy\", \"taste\", \"time\", \"drink\", \"flavor\", \"look\", \"recommend\", \"love\", \"favorite\", \"good\", \"find\", \"come\", \"try\", \"great\", \"box\", \"product\", \"baby\", \"receive\", \"consistency\", \"meat\", \"real\", \"decide\", \"delivery\", \"miss\", \"wrong\", \"offer\", \"version\", \"disappoint\", \"tasting\", \"ask\", \"tooth\", \"child\", \"crunch\", \"crisp\", \"mom\", \"stick\", \"choose\", \"supermarket\", \"gum\", \"cat\", \"old\", \"intake\", \"suggest\", \"process\", \"father\", \"kitchen\", \"quality\", \"c\", \"worth\", \"organic\", \"month\", \"vitamin\", \"ounce\", \"price\", \"excellent\", \"good\", \"know\", \"product\", \"potato\", \"try\", \"food\", \"year\", \"great\", \"bag\", \"love\", \"high\", \"eat\", \"thank\", \"buy\", \"store\", \"ingredient\", \"tasty\", \"snack\", \"taste\", \"find\", \"like\", \"sweet\", \"get\", \"spicy\", \"far\", \"sauce\", \"money\", \"bring\", \"recipe\", \"rice\", \"caramel\", \"mean\", \"hope\", \"brown\", \"flavour\", \"service\", \"soon\", \"night\", \"label\", \"grab\", \"habanero\", \"gourmet\", \"deep\", \"grain\", \"roll\", \"awful\", \"personal\", \"easily\", \"normally\", \"trip\", \"lose\", \"power\", \"soak\", \"oil\", \"hot\", \"heat\", \"vegetable\", \"fine\", \"'\", \"balance\", \"issue\", \"corn\", \"dry\", \"food\", \"potato\", \"add\", \"soy\", \"flavor\", \"good\", \"mix\", \"like\", \"want\", \"different\", \"ingredient\", \"sweet\", \"eat\", \"little\", \"chip\", \"love\", \"favorite\", \"bottle\", \"brand\", \"taste\", \"try\", \"kettle\", \"find\", \"bar\", \"salt\", \"line\", \"fast\", \"sea\", \"pop\", \"salty\", \"not\", \"set\", \"surprised\", \"dish\", \"value\", \"fiber\", \"asian\", \"control\", \"middle\", \"nutrition\", \"season\", \"post\", \"dairy\", \"mouth\", \"suppose\", \"grow\", \"regularly\", \"acid\", \"terrible\", \"deliver\", \"gluten\", \"tired\", \"steal\", \"chip\", \"artificial\", \"vinegar\", \"cookie\", \"flour\", \"remind\", \"kettle\", \"family\", \"one\", \"taste\", \"bad\", \"product\", \"flavor\", \"brand\", \"like\", \"try\", \"perfect\", \"nice\", \"star\", \"actually\", \"eat\", \"great\", \"love\", \"buy\", \"good\", \"go\", \"find\", \"sweet\", \"son\", \"dinner\", \"expect\", \"carry\", \"exactly\", \"finally\", \"strawberry\", \"salsa\", \"hold\", \"peanut\", \"fry\", \"tart\", \"chemical\", \"hit\", \"quick\", \"shipment\", \"plastic\", \"watch\", \"nut\", \"christmas\", \"dad\", \"girl\", \"careful\", \"expiration\", \"pot\", \"take\", \"spot\", \"website\", \"pain\", \"ton\", \"business\", \"provide\", \"glad\", \"fun\", \"date\", \"butter\", \"stock\", \"thin\", \"allergy\", \"jar\", \"earth\", \"box\", \"great\", \"look\", \"find\", \"use\", \"fruit\", \"love\", \"size\", \"good\", \"price\", \"time\", \"water\", \"taste\", \"eat\", \"way\", \"sugar\", \"like\", \"buy\"], \"Total\": [503.0, 222.0, 128.0, 101.0, 84.0, 91.0, 67.0, 136.0, 124.0, 263.0, 150.0, 267.0, 87.0, 67.0, 60.0, 57.0, 45.0, 74.0, 244.0, 344.0, 465.0, 48.0, 67.0, 241.0, 131.0, 137.0, 42.0, 130.0, 82.0, 51.0, 42.185184478759766, 36.55056381225586, 32.89517593383789, 31.788022994995117, 33.0368537902832, 26.61735725402832, 26.66412925720215, 24.6480770111084, 25.235591888427734, 19.731786727905273, 27.8427677154541, 17.76565170288086, 17.371097564697266, 16.70723533630371, 32.638832092285156, 16.19316864013672, 16.186283111572266, 14.251550674438477, 13.780529022216797, 15.072786331176758, 22.287321090698242, 14.919102668762207, 20.046907424926758, 12.642623901367188, 12.648646354675293, 29.782455444335938, 11.30981159210205, 10.65211296081543, 37.6729736328125, 10.571365356445312, 222.93966674804688, 53.79056167602539, 48.69470977783203, 150.4176788330078, 38.96929168701172, 130.6163787841797, 38.58815002441406, 82.25595092773438, 33.67160415649414, 140.5819549560547, 39.611183166503906, 56.708492279052734, 263.39410400390625, 41.0534782409668, 61.628211975097656, 58.03939437866211, 109.94613647460938, 451.17535400390625, 78.1414794921875, 228.0330352783203, 366.50054931640625, 161.8372344970703, 54.19457244873047, 344.2969665527344, 115.71717834472656, 76.90802764892578, 291.2601013183594, 121.03837585449219, 465.17706298828125, 204.28538513183594, 99.35343170166016, 224.06826782226562, 241.67916870117188, 91.24225616455078, 244.99317932128906, 128.27841186523438, 40.92219543457031, 37.339210510253906, 32.8478889465332, 31.5537052154541, 21.994548797607422, 18.706472396850586, 18.146127700805664, 16.79638671875, 15.863920211791992, 17.419328689575195, 14.129429817199707, 23.153133392333984, 11.561616897583008, 11.467196464538574, 13.753365516662598, 17.796907424926758, 10.267454147338867, 10.165197372436523, 51.55686950683594, 9.46931266784668, 12.574346542358398, 18.236143112182617, 9.400857925415039, 74.15902709960938, 7.755024433135986, 8.409351348876953, 15.692988395690918, 8.484504699707031, 9.610028266906738, 67.77484893798828, 18.98063087463379, 15.893238067626953, 124.74007415771484, 76.96600341796875, 36.20612335205078, 25.858366012573242, 137.1329803466797, 44.26891326904297, 465.17706298828125, 98.9578857421875, 244.99317932128906, 136.3621063232422, 224.06826782226562, 267.32781982421875, 57.92723846435547, 241.67916870117188, 263.39410400390625, 291.2601013183594, 52.67124938964844, 218.90591430664062, 52.984535217285156, 228.0330352783203, 101.48541259765625, 87.04776763916016, 69.81305694580078, 65.52880096435547, 366.50054931640625, 204.28538513183594, 451.17535400390625, 110.81767272949219, 88.06202697753906, 60.65897750854492, 57.39766311645508, 91.92559814453125, 28.15365219116211, 20.89284324645996, 19.871009826660156, 67.34465789794922, 26.621658325195312, 16.54670524597168, 16.588193893432617, 42.74580764770508, 14.002676010131836, 11.655845642089844, 10.196393013000488, 10.577699661254883, 21.71131134033203, 9.544002532958984, 10.093441009521484, 9.180010795593262, 8.965970993041992, 10.236553192138672, 8.97193717956543, 7.131234169006348, 7.545284748077393, 9.069547653198242, 6.728428840637207, 6.5963358879089355, 13.238789558410645, 6.455359935760498, 6.996016979217529, 34.770408630371094, 87.5037612915039, 17.4129581451416, 36.397361755371094, 27.21739387512207, 44.42852783203125, 17.94772720336914, 29.981033325195312, 18.86421775817871, 21.949016571044922, 267.32781982421875, 136.3621063232422, 103.5450668334961, 32.17333984375, 344.2969665527344, 465.17706298828125, 60.83112716674805, 451.17535400390625, 107.20242309570312, 48.538124084472656, 87.04776763916016, 110.81767272949219, 218.90591430664062, 87.7221450805664, 503.1217956542969, 291.2601013183594, 121.03837585449219, 55.272342681884766, 134.6818084716797, 366.50054931640625, 224.06826782226562, 131.54995727539062, 204.28538513183594, 84.20130157470703, 101.44441986083984, 22.666715621948242, 19.782838821411133, 22.79283905029297, 17.917558670043945, 34.91835021972656, 31.042448043823242, 12.246786117553711, 19.95964813232422, 16.597288131713867, 13.84226131439209, 11.783721923828125, 11.555498123168945, 12.608489990234375, 8.623491287231445, 8.393074989318848, 11.792627334594727, 9.103401184082031, 7.703578948974609, 35.360687255859375, 9.298590660095215, 11.343122482299805, 8.643065452575684, 9.866361618041992, 10.108312606811523, 13.504676818847656, 23.827428817749023, 16.67454719543457, 7.017983436584473, 503.1217956542969, 15.266186714172363, 45.278533935546875, 54.781986236572266, 20.99421501159668, 14.553705215454102, 131.54995727539062, 45.633602142333984, 36.80081558227539, 366.50054931640625, 62.15766525268555, 244.99317932128906, 344.2969665527344, 134.6818084716797, 451.17535400390625, 224.06826782226562, 36.385616302490234, 64.11692810058594, 36.582305908203125, 52.526546478271484, 218.90591430664062, 241.67916870117188, 291.2601013183594, 228.0330352783203, 465.17706298828125, 79.93543243408203, 204.28538513183594, 110.81767272949219, 67.95986938476562, 45.446868896484375, 32.299137115478516, 24.303794860839844, 13.40899658203125, 10.905655860900879, 25.047197341918945, 12.497055053710938, 11.08127498626709, 23.843299865722656, 9.733992576599121, 9.68480396270752, 9.5059175491333, 13.607902526855469, 14.701713562011719, 7.545024394989014, 48.65895080566406, 10.840020179748535, 8.249683380126953, 10.855064392089844, 6.647027969360352, 13.268899917602539, 9.85089111328125, 10.682845115661621, 6.984979629516602, 42.47394561767578, 6.256458282470703, 6.016570091247559, 5.875490665435791, 5.85947847366333, 9.798391342163086, 9.37264633178711, 20.651952743530273, 19.829341888427734, 26.312185287475586, 24.051042556762695, 19.20285415649414, 14.229089736938477, 15.249957084655762, 62.11491394042969, 65.99540710449219, 91.24225616455078, 241.67916870117188, 115.71717834472656, 204.28538513183594, 135.51649475097656, 48.641990661621094, 291.2601013183594, 52.71437072753906, 465.17706298828125, 137.1329803466797, 161.8372344970703, 76.0938491821289, 366.50054931640625, 218.90591430664062, 54.181495666503906, 65.22029113769531, 451.17535400390625, 228.0330352783203], \"loglift\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, 1.266800045967102, 1.2626999616622925, 1.2597999572753906, 1.2595000267028809, 1.2582000494003296, 1.257099986076355, 1.2563999891281128, 1.2544000148773193, 1.2513999938964844, 1.2474000453948975, 1.2438000440597534, 1.2411999702453613, 1.2411999702453613, 1.239799976348877, 1.2396999597549438, 1.2389999628067017, 1.2337000370025635, 1.2329000234603882, 1.230299949645996, 1.2280000448226929, 1.2279000282287598, 1.2274999618530273, 1.2233999967575073, 1.2226999998092651, 1.2217999696731567, 1.2208000421524048, 1.217900037765503, 1.2145999670028687, 1.214400053024292, 1.2110999822616577, 1.2080999612808228, 1.186900019645691, 1.1863000392913818, 1.1395000219345093, 1.1721999645233154, 1.0532000064849854, 1.146399974822998, 1.0743000507354736, 1.1545000076293945, 1.0085999965667725, 1.128000020980835, 1.0420000553131104, 0.7764999866485596, 1.0672999620437622, 0.98089998960495, 0.9718999862670898, 0.7397000193595886, 0.17720000445842743, 0.8159999847412109, 0.33000001311302185, 0.0877000018954277, 0.41909998655319214, 0.9318000078201294, 0.0027000000700354576, 0.5435000061988831, 0.7390999794006348, -0.24539999663829803, 0.3149999976158142, -0.7056999802589417, -0.1469999998807907, 0.3725999891757965, -0.3061000108718872, -0.438400000333786, 0.42590001225471497, -0.5490000247955322, 1.5465999841690063, 1.5356999635696411, 1.5329999923706055, 1.5267000198364258, 1.5175000429153442, 1.5145000219345093, 1.5144000053405762, 1.5108000040054321, 1.5074000358581543, 1.5063999891281128, 1.5049999952316284, 1.4997999668121338, 1.4916000366210938, 1.4888999462127686, 1.4880000352859497, 1.4818999767303467, 1.4803999662399292, 1.4788000583648682, 1.476199984550476, 1.4735000133514404, 1.4728000164031982, 1.462399959564209, 1.4621000289916992, 1.4605000019073486, 1.455399990081787, 1.4486000537872314, 1.4484000205993652, 1.4462000131607056, 1.4377000331878662, 1.434999942779541, 1.4104000329971313, 1.416100025177002, 1.4117000102996826, 1.2867000102996826, 1.2695000171661377, 1.2927000522613525, 1.3264000415802002, 0.9896000027656555, 1.1516000032424927, 0.5633000135421753, 0.9333000183105469, 0.6812000274658203, 0.8346999883651733, 0.6209999918937683, 0.5080999732017517, 1.0204999446868896, 0.4878000020980835, 0.4521999955177307, 0.3714999854564667, 1.0356999635696411, 0.414000004529953, 1.0132999420166016, 0.3328000009059906, 0.7113999724388123, 0.7372000217437744, 0.8607000112533569, 0.8956999778747559, -0.3785000145435333, 0.04190000146627426, -0.6365000009536743, 0.4381999969482422, 0.5875999927520752, 1.6296000480651855, 1.628499984741211, 1.6197999715805054, 1.613800048828125, 1.6061999797821045, 1.604599952697754, 1.5986000299453735, 1.597599983215332, 1.5968999862670898, 1.596500039100647, 1.5963000059127808, 1.5770000219345093, 1.57669997215271, 1.566100001335144, 1.565600037574768, 1.5621000528335571, 1.5613000392913818, 1.5599000453948975, 1.5598000288009644, 1.5442999601364136, 1.5434999465942383, 1.5325000286102295, 1.5318000316619873, 1.5299999713897705, 1.5285999774932861, 1.52839994430542, 1.5236999988555908, 1.5233999490737915, 1.5226999521255493, 1.5211999416351318, 1.510599970817566, 1.4940999746322632, 1.4919999837875366, 1.4488999843597412, 1.4501999616622925, 1.4154000282287598, 1.4670000076293945, 1.3946000337600708, 1.4352999925613403, 1.3779000043869019, 0.8371999859809875, 0.9577000141143799, 0.9757000207901001, 1.2661999464035034, 0.588100016117096, 0.41940000653266907, 1.0299999713897705, 0.33709999918937683, 0.8282999992370605, 1.0793999433517456, 0.8219000101089478, 0.6730999946594238, 0.2989000082015991, 0.7175999879837036, -0.4059000015258789, -0.14880000054836273, 0.42170000076293945, 0.9211999773979187, 0.2833999991416931, -0.5609999895095825, -0.2824999988079071, 0.13510000705718994, -0.274399995803833, 1.7415000200271606, 1.7211999893188477, 1.719599962234497, 1.7158000469207764, 1.7130000591278076, 1.7098000049591064, 1.7091000080108643, 1.7009999752044678, 1.6920000314712524, 1.6888999938964844, 1.6845999956130981, 1.6800999641418457, 1.6794999837875366, 1.673699975013733, 1.667799949645996, 1.6653000116348267, 1.6634999513626099, 1.6589000225067139, 1.657099962234497, 1.6536999940872192, 1.6527999639511108, 1.6497999429702759, 1.6446000337600708, 1.6446000337600708, 1.6419999599456787, 1.6390000581741333, 1.6333999633789062, 1.6282999515533447, 1.628000020980835, 1.6273000240325928, 1.565500020980835, 1.6013000011444092, 1.5118999481201172, 1.4886000156402588, 1.5217000246047974, 1.570199966430664, 1.1405999660491943, 1.333899974822998, 1.3051999807357788, 0.6678000092506409, 1.128000020980835, 0.6399000287055969, 0.44200000166893005, 0.7882999777793884, 0.25699999928474426, 0.325300008058548, 1.1764999628067017, 0.8985999822616577, 1.1629999876022339, 0.9587000012397766, 0.05689999833703041, -0.07919999957084656, -0.3158999979496002, -0.21969999372959137, -0.8927000164985657, 0.5205000042915344, -0.3427000045776367, 0.09640000015497208, 1.9220999479293823, 1.9155999422073364, 1.9104000329971313, 1.902899980545044, 1.877500057220459, 1.8628000020980835, 1.8617000579833984, 1.8601000308990479, 1.8597999811172485, 1.8574999570846558, 1.8559000492095947, 1.855299949645996, 1.8535000085830688, 1.8517999649047852, 1.836400032043457, 1.8316999673843384, 1.827299952507019, 1.8220000267028809, 1.8207999467849731, 1.8206000328063965, 1.8178000450134277, 1.8151999711990356, 1.8125, 1.809999942779541, 1.8087999820709229, 1.8062000274658203, 1.805400013923645, 1.8035999536514282, 1.801900029182434, 1.8001999855041504, 1.7888000011444092, 1.788599967956543, 1.746899962425232, 1.7259999513626099, 1.6979999542236328, 1.7015000581741333, 1.641800045967102, 1.6820000410079956, 1.653499960899353, 1.2403000593185425, 1.2160999774932861, 1.059399962425232, 0.6471999883651733, 0.8849999904632568, 0.625, 0.77920001745224, 1.1157000064849854, 0.23810000717639923, 1.0463999509811401, -0.1356000006198883, 0.48240000009536743, 0.38850000500679016, 0.6988999843597412, -0.3264000117778778, -0.07079999893903732, 0.8853999972343445, 0.7081000208854675, -0.8461999893188477, -0.41600000858306885], \"logprob\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, -5.352799892425537, -5.50029993057251, -5.60860013961792, -5.643099784851074, -5.605800151824951, -5.822999954223633, -5.821899890899658, -5.902500152587891, -5.881999969482422, -6.131999969482422, -5.791299819946289, -6.243199825286865, -6.265699863433838, -6.306099891662598, -5.63640022277832, -6.338099956512451, -6.343900203704834, -6.47189998626709, -6.5081000328063965, -6.42080020904541, -6.029799938201904, -6.431600093841553, -6.140200138092041, -6.601900100708008, -6.60230016708374, -5.747000217437744, -6.718100070953369, -6.781300067901611, -5.5183000564575195, -6.792399883270264, -3.7467000484466553, -5.189599990844727, -5.28980016708374, -4.208700180053711, -5.526700019836426, -4.436200141906738, -5.562300205230713, -4.877500057220459, -5.690499782562256, -4.407299995422363, -5.554599761962891, -5.281700134277344, -4.011499881744385, -5.579500198364258, -5.2596001625061035, -5.328700065612793, -4.921999931335449, -4.0725998878479, -5.18720006942749, -4.602200031280518, -4.369900226593018, -4.855999946594238, -5.437300205230713, -4.517499923706055, -5.066999912261963, -5.279900074005127, -4.932799816131592, -5.250500202178955, -4.925000190734863, -5.189199924468994, -5.390399932861328, -5.255799770355225, -5.3125, -5.4222002029418945, -5.40939998626709, -3.960900068283081, -5.114299774169922, -5.208700180053711, -5.343100070953369, -5.392399787902832, -5.756400108337402, -5.918399810791016, -5.952400207519531, -6.033100128173828, -6.09119987487793, -5.999100208282471, -6.213600158691406, -5.728000164031982, -6.425099849700928, -6.434100151062012, -6.258500099182129, -6.002299785614014, -6.553899765014648, -6.566500186920166, -4.945499897003174, -6.6407999992370605, -6.367599964141846, -5.996200084686279, -6.660399913787842, -4.600100040435791, -6.864699840545654, -6.783899784088135, -6.162300109863281, -6.785699844360352, -6.66379976272583, -4.735000133514404, -6.002099990844727, -6.184100151062012, -4.248799800872803, -4.748799800872803, -5.479700088500977, -5.782599925994873, -4.451099872589111, -5.4197998046875, -3.655900001525879, -4.833700180053711, -4.179299831390381, -4.611599922180176, -4.328700065612793, -4.265100002288818, -5.281899929046631, -4.386199951171875, -4.3358001708984375, -4.315999984741211, -5.3618998527526855, -4.559000015258789, -5.378399848937988, -4.599400043487549, -5.030399799346924, -5.1579999923706055, -5.255099773406982, -5.283400058746338, -4.83620023727417, -5.000199794769287, -4.886300086975098, -5.2154998779296875, -5.29610013961792, -4.626800060272217, -4.683199882507324, -4.220900058746338, -5.410200119018555, -5.716100215911865, -5.7677998542785645, -4.553199768066406, -5.482399940490723, -5.958600044250488, -5.956500053405762, -5.0100998878479, -6.145400047302246, -6.32919979095459, -6.473499774932861, -6.437300205230713, -5.721799850463867, -6.54449987411499, -6.4899001121521, -6.584799766540527, -6.623899936676025, -6.492300033569336, -6.6350998878479, -6.8653998374938965, -6.810699939727783, -6.628200054168701, -6.9268999099731445, -6.951499938964844, -6.255099773406982, -6.974100112915039, -6.895100116729736, -5.302299976348877, -4.395899772644043, -6.012400150299072, -5.318299770355225, -5.607600212097168, -5.152400016784668, -6.007199764251709, -5.566500186920166, -5.989099979400635, -5.895100116729736, -3.936000108718872, -4.48859977722168, -4.7459001541137695, -5.624300003051758, -3.931999921798706, -3.799799919128418, -5.223599910736084, -3.9126999378204346, -4.85860013961792, -5.399899959564209, -5.073299884796143, -4.9807000160217285, -4.674099922180176, -5.169899940490723, -4.5467000007629395, -4.836299896240234, -5.143899917602539, -5.428199768066406, -5.175300121307373, -5.018599987030029, -5.2322998046875, -5.3471999168396, -5.3165998458862305, -4.186999797821045, -4.020899772644043, -5.521200180053711, -5.661099910736084, -5.522200107574463, -5.76609992980957, -5.099599838256836, -5.225299835205078, -6.1645002365112305, -5.679100036621094, -5.867800235748291, -6.053800106048584, -6.215400218963623, -6.240799903869629, -6.1595001220703125, -6.541900157928467, -6.570700168609619, -6.235300064086914, -6.4959001541137695, -6.666299819946289, -5.1433000564575195, -6.48199987411499, -6.28849983215332, -6.560400009155273, -6.430500030517578, -6.409299850463867, -6.125199794769287, -5.5625, -5.9197998046875, -6.785900115966797, -2.5752999782562256, -6.0346999168396, -5.0370001792907715, -4.869699954986572, -5.7957000732421875, -6.113699913024902, -4.341700077056885, -5.207099914550781, -5.451000213623047, -3.789799928665161, -5.104000091552734, -4.220600128173828, -4.078199863433838, -4.670499801635742, -3.9928998947143555, -4.6244001388549805, -5.591000080108643, -5.302299976348877, -5.599100112915039, -5.441699981689453, -4.916200160980225, -4.9532999992370605, -5.003399848937988, -5.151899814605713, -5.1118998527526855, -5.45989990234375, -5.384900093078613, -5.557400226593018, -4.220699787139893, -4.629499912261963, -4.976200103759766, -5.268099784851074, -5.888199806213379, -6.109600067138672, -5.279200077056885, -5.976099967956543, -6.096700191497803, -5.332699775695801, -6.230199813842773, -6.235899925231934, -6.25629997253418, -5.899199962615967, -5.837299823760986, -6.508999824523926, -4.649499893188477, -6.156400203704834, -6.430699825286865, -6.156400203704834, -6.649700164794922, -5.961100101470947, -6.261600017547607, -6.183000087738037, -6.609099864959717, -4.806600093841553, -6.722599983215332, -6.763500213623047, -6.789000034332275, -6.793399810791016, -6.290599822998047, -6.335299968719482, -5.586999893188477, -5.648499965667725, -5.393599987030029, -5.480000019073486, -5.764800071716309, -6.024400234222412, -5.98360013961792, -4.992300033569336, -4.955999851226807, -4.78879976272583, -4.226799964904785, -4.725500106811523, -4.417200088500977, -4.673299789428711, -5.361499786376953, -4.449399948120117, -5.350399971008301, -4.354899883270264, -4.9583001136779785, -4.886600017547607, -5.3308000564575195, -4.78410005569458, -5.043900012969971, -5.48390007019043, -5.475800037384033, -5.096099853515625, -5.348199844360352]}, \"token.table\": {\"Topic\": [1, 2, 3, 5, 1, 4, 1, 3, 4, 5, 1, 2, 3, 4, 5, 1, 1, 1, 1, 3, 5, 1, 2, 3, 5, 1, 4, 5, 4, 2, 3, 2, 1, 2, 3, 4, 5, 1, 2, 3, 5, 1, 3, 4, 1, 3, 5, 1, 1, 1, 5, 1, 3, 4, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 3, 3, 4, 5, 5, 1, 3, 4, 5, 1, 2, 3, 4, 5, 2, 5, 3, 5, 5, 2, 5, 1, 1, 2, 1, 3, 4, 1, 2, 3, 4, 5, 2, 1, 5, 1, 2, 3, 5, 1, 2, 3, 4, 5, 2, 4, 1, 2, 3, 4, 5, 2, 3, 1, 3, 2, 2, 1, 2, 3, 5, 5, 4, 1, 4, 5, 2, 3, 1, 3, 5, 1, 2, 3, 4, 5, 3, 4, 2, 1, 2, 3, 5, 2, 2, 4, 1, 2, 3, 4, 5, 1, 3, 1, 2, 3, 4, 5, 3, 1, 2, 3, 4, 5, 1, 2, 5, 2, 3, 5, 5, 5, 1, 1, 2, 4, 5, 3, 4, 2, 1, 2, 3, 4, 4, 5, 1, 2, 3, 4, 5, 3, 4, 1, 2, 3, 4, 5, 3, 1, 3, 4, 1, 2, 3, 4, 5, 1, 2, 4, 5, 5, 1, 5, 1, 2, 3, 4, 5, 5, 3, 5, 1, 4, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 3, 3, 3, 1, 2, 3, 4, 5, 1, 2, 3, 2, 4, 1, 2, 3, 1, 2, 3, 1, 2, 3, 4, 5, 5, 5, 1, 5, 3, 1, 3, 5, 1, 2, 1, 1, 2, 3, 5, 2, 1, 2, 3, 1, 2, 3, 5, 1, 3, 5, 1, 2, 3, 4, 5, 2, 4, 1, 2, 3, 4, 5, 1, 3, 1, 3, 1, 1, 1, 2, 3, 4, 5, 4, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 3, 4, 1, 2, 3, 4, 5, 3, 2, 1, 4, 2, 1, 2, 3, 5, 2, 3, 1, 2, 3, 4, 1, 4, 1, 1, 2, 4, 3, 3, 1, 4, 5, 4, 2, 1, 3, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 1, 3, 5, 1, 2, 3, 4, 5, 1, 2, 5, 2, 3, 4, 1, 5, 1, 4, 5, 1, 2, 4, 3, 1, 1, 4, 5, 4, 4, 5, 2, 3, 4, 3, 1, 2, 3, 4, 5, 2, 3, 1, 2, 3, 4, 5, 1, 3, 4, 1, 5, 1, 2, 3, 4, 5, 2, 3, 4, 5, 5, 2, 5, 2, 3, 1, 2, 3, 4, 5, 1, 4, 3, 4, 1, 1, 2, 3, 3, 5, 2, 3, 4, 5, 1, 4, 3, 5, 4, 2, 4, 1, 1, 3, 4, 1, 5, 5, 1, 2, 3, 4, 5, 1, 1, 2, 3, 5, 3, 1, 2, 3, 4, 3, 5, 1, 2, 3, 4, 5, 4, 1, 2, 5, 2, 5, 1, 2, 3, 4, 5, 2, 5, 1, 2, 3, 4, 5, 2, 1, 2, 4, 1, 4, 1, 2, 3, 4, 5, 4, 5, 5, 1, 2, 3, 4, 5, 1, 2, 1, 2, 3, 4, 1, 2, 1, 4, 1, 2, 3, 5, 1, 2, 3, 4, 4, 5, 1, 2, 3, 4, 5, 4, 5, 5, 2, 3, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 4, 1, 3, 4, 2, 1, 2, 3, 4, 5, 1, 2, 4, 1, 2, 3, 4, 5, 1, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 5, 2, 5, 2, 1, 2, 3, 4, 5], \"Freq\": [0.13504835963249207, 0.04501612111926079, 0.7877821326255798, 0.022508060559630394, 0.9750927686691284, 0.9121903777122498, 0.2474939078092575, 0.22845591604709625, 0.4569118320941925, 0.07615196704864502, 0.28007128834724426, 0.1641797125339508, 0.5118544101715088, 0.009657630696892738, 0.028972892090678215, 0.9487181305885315, 0.9383942484855652, 0.9433600306510925, 0.13114790618419647, 0.13114790618419647, 0.7868874669075012, 0.5821031928062439, 0.24557480216026306, 0.054572176188230515, 0.11823971569538116, 0.06550424546003342, 0.8515551686286926, 0.06550424546003342, 0.9519277811050415, 0.9514240026473999, 0.841369092464447, 0.9900341033935547, 0.37002676725387573, 0.048264361917972565, 0.032176241278648376, 0.5309079885482788, 0.016088120639324188, 0.603658139705658, 0.3341001272201538, 0.03037273697555065, 0.034169331192970276, 0.11143472045660019, 0.8357604146003723, 0.9857329726219177, 0.8583434820175171, 0.02524539642035961, 0.10098158568143845, 0.9510377049446106, 0.9263165593147278, 0.940150797367096, 0.03357681632041931, 0.18092231452465057, 0.4884902536869049, 0.32566016912460327, 0.4274335205554962, 0.08767867088317871, 0.03287950158119202, 0.03287950158119202, 0.4164736866950989, 0.14107324182987213, 0.1633479744195938, 0.25987178087234497, 0.3786703050136566, 0.05939926207065582, 0.9768062233924866, 0.9572656154632568, 0.9591583609580994, 0.023394107818603516, 0.023394107818603516, 0.8164605498313904, 0.12473471462726593, 0.04157824069261551, 0.04157824069261551, 0.7899865508079529, 0.38590899109840393, 0.29381707310676575, 0.08332125842571259, 0.14033053815364838, 0.09647724777460098, 0.8956499099731445, 0.10537057369947433, 0.9390850067138672, 0.9136229157447815, 0.9875001311302185, 0.9573594331741333, 0.9467786550521851, 0.9491700530052185, 0.9686152338981628, 0.9452232122421265, 0.0397518053650856, 0.12919336557388306, 0.8288251757621765, 0.7962247729301453, 0.06890407204627991, 0.0612480603158474, 0.06890407204627991, 0.007656007539480925, 0.9504385590553284, 0.09212289750576019, 0.9212290048599243, 0.8642601370811462, 0.09972231835126877, 0.013296309858560562, 0.019944464787840843, 0.4026030898094177, 0.050325386226177216, 0.23149678111076355, 0.17110632359981537, 0.15097616612911224, 0.9909154176712036, 0.9517396688461304, 0.10952505469322205, 0.0730167031288147, 0.018254175782203674, 0.7666753530502319, 0.03650835156440735, 0.1590312421321869, 0.7951562404632568, 0.9477770924568176, 0.049883004277944565, 0.9739512801170349, 0.9552221298217773, 0.7236464023590088, 0.17229676246643066, 0.0516890287399292, 0.03445935249328613, 0.9026590585708618, 0.908668577671051, 0.07601041346788406, 0.1140156164765358, 0.7981092929840088, 0.9547820091247559, 0.8922625184059143, 0.8810995221138, 0.025914691388607025, 0.1036587655544281, 0.7935319542884827, 0.10580425709486008, 0.017634043470025063, 0.017634043470025063, 0.07053617388010025, 0.07404842227697372, 0.8885810375213623, 0.9622337818145752, 0.35024014115333557, 0.06180708482861519, 0.5768661499023438, 0.9901672005653381, 0.9200654625892639, 0.06025080755352974, 0.9640129208564758, 0.7011772394180298, 0.20297235250473022, 0.018452031537890434, 0.03690406307578087, 0.05535609647631645, 0.18224051594734192, 0.7745221853256226, 0.06061027944087982, 0.15152569115161896, 0.22728854417800903, 0.06061027944087982, 0.4848822355270386, 0.8820726871490479, 0.10049979388713837, 0.3197720944881439, 0.2603858411312103, 0.1827269047498703, 0.13704517483711243, 0.8145307302474976, 0.18235762417316437, 0.969498336315155, 0.6776764392852783, 0.09035685658454895, 0.22589215636253357, 0.990738570690155, 0.8424721956253052, 0.9726068377494812, 0.0438273549079895, 0.262964129447937, 0.6574103236198425, 0.0438273549079895, 0.9930717945098877, 0.9604284167289734, 0.9428953528404236, 0.38004475831985474, 0.1817605346441269, 0.29742634296417236, 0.1404513269662857, 0.9334911108016968, 0.9169554114341736, 0.23986051976680756, 0.22028008103370667, 0.14685338735580444, 0.12237782031297684, 0.2692312002182007, 0.8083066344261169, 0.14696484804153442, 0.27882906794548035, 0.07551620155572891, 0.34853631258010864, 0.2701156437397003, 0.02904469333589077, 0.9283939599990845, 0.09526433795690536, 0.09526433795690536, 0.8097468614578247, 0.13466611504554749, 0.35162821412086487, 0.44888705015182495, 0.007481451146304607, 0.05611088126897812, 0.06167510896921158, 0.14390859007835388, 0.34949228167533875, 0.43172574043273926, 0.9245949387550354, 0.15129095315933228, 0.8068850636482239, 0.37473586201667786, 0.3860915005207062, 0.06813379377126694, 0.09084505587816238, 0.09084505587816238, 0.9043703675270081, 0.14526471495628357, 0.8231667280197144, 0.08393687754869461, 0.8813372254371643, 0.1251009702682495, 0.27522212266921997, 0.16263125836849213, 0.28773221373558044, 0.15012116730213165, 0.13758201897144318, 0.37190139293670654, 0.29451149702072144, 0.07094072550535202, 0.12683342397212982, 0.8714586496353149, 0.9430006146430969, 0.8792021870613098, 0.1779218316078186, 0.3434305191040039, 0.04137716814875603, 0.16137096285820007, 0.2772270441055298, 0.8909584283828735, 0.08909584581851959, 0.02969861403107643, 0.08815914392471313, 0.8815914392471313, 0.05483615770936012, 0.9322146773338318, 0.8916681408882141, 0.057428497821092606, 0.057428497821092606, 0.8614274263381958, 0.17087121307849884, 0.5885564088821411, 0.09492845088243484, 0.05695706978440285, 0.075942762196064, 0.9553272724151611, 0.9024232625961304, 0.9497888684272766, 0.030638352036476135, 0.9645414352416992, 0.06856848299503326, 0.8685340881347656, 0.05714040249586105, 0.9422397613525391, 0.04486855864524841, 0.9387809038162231, 0.11487945169210434, 0.43654191493988037, 0.43654191493988037, 0.011487944982945919, 0.9026406407356262, 0.16677209734916687, 0.033354420214891434, 0.7671516537666321, 0.9290480017662048, 0.026544228196144104, 0.026544228196144104, 0.026544228196144104, 0.11269435286521912, 0.3863806426525116, 0.4990749955177307, 0.08361842483282089, 0.11402512341737747, 0.2204485684633255, 0.5397189259529114, 0.038008373230695724, 0.9365217089653015, 0.10405796766281128, 0.2324220985174179, 0.5355813503265381, 0.16168494522571564, 0.020210618153214455, 0.05052654445171356, 0.04605894163250923, 0.9211788177490234, 0.803829550743103, 0.17050930857658386, 0.9267106056213379, 0.9629133343696594, 0.33024853467941284, 0.11082165688276291, 0.2704048454761505, 0.2238597422838211, 0.06206012889742851, 0.9705861210823059, 0.1595948189496994, 0.27359113097190857, 0.3989870548248291, 0.04559852182865143, 0.12539592385292053, 0.4752967655658722, 0.05185055732727051, 0.06913407146930695, 0.05185055732727051, 0.35431212186813354, 0.906427264213562, 0.0755356103181839, 0.21630151569843292, 0.3055688142776489, 0.16823451220989227, 0.12703421711921692, 0.18196794390678406, 0.9669598937034607, 0.974187433719635, 0.9727870225906372, 0.9276984930038452, 0.9368389844894409, 0.24658428132534027, 0.016438951715826988, 0.5424854159355164, 0.19726742804050446, 0.8853738307952881, 0.9590229988098145, 0.10394199937582016, 0.7535794973373413, 0.05197099968791008, 0.09094924479722977, 0.08483997732400894, 0.9049597978591919, 0.9569026827812195, 0.4990881681442261, 0.06238602101802826, 0.42110565304756165, 0.9453851580619812, 0.8917386531829834, 0.032213952392339706, 0.9342046976089478, 0.8485174179077148, 0.9531667232513428, 0.9455417990684509, 0.028760086745023727, 0.8915627002716064, 0.057520173490047455, 0.040453605353832245, 0.9034638404846191, 0.040453605353832245, 0.013484534807503223, 0.013484534807503223, 0.02717331051826477, 0.05434662103652954, 0.21738648414611816, 0.6521594524383545, 0.05434662103652954, 0.9697311520576477, 0.9109404683113098, 0.03718124330043793, 0.03718124330043793, 0.7611218690872192, 0.09247274696826935, 0.09247274696826935, 0.007113288622349501, 0.04979301989078522, 0.21645009517669678, 0.7615836262702942, 0.016033340245485306, 0.812116265296936, 0.15468882024288177, 0.038672205060720444, 0.9719051718711853, 0.850992739200592, 0.04194050282239914, 0.04194050282239914, 0.9226910471916199, 0.38476741313934326, 0.054966773837804794, 0.5496677756309509, 0.9277316927909851, 0.9849369525909424, 0.020551202818751335, 0.08220481127500534, 0.9042529463768005, 0.9487899541854858, 0.878792405128479, 0.8589860200881958, 0.4840054214000702, 0.5060057044029236, 0.007333415560424328, 0.9294601678848267, 0.05104534327983856, 0.5687909722328186, 0.04375315085053444, 0.10209068655967712, 0.23335014283657074, 0.8921181559562683, 0.06372272968292236, 0.15918810665607452, 0.41633811593055725, 0.07755318284034729, 0.3306214511394501, 0.016326984390616417, 0.9035888910293579, 0.06160833686590195, 0.020536111667752266, 0.10669345408678055, 0.8535476326942444, 0.6270677447319031, 0.10237840563058853, 0.012797300703823566, 0.20475681126117706, 0.06398650258779526, 0.8705294132232666, 0.08852841705083847, 0.014754735864698887, 0.014754735864698887, 0.8842506408691406, 0.9507599472999573, 0.03169199824333191, 0.9774646759033203, 0.9561668038368225, 0.5851144790649414, 0.19503815472126007, 0.07801526039838791, 0.13002543151378632, 0.013002543710172176, 0.9752100706100464, 0.9255975484848022, 0.13742205500602722, 0.8245322704315186, 0.9576689004898071, 0.029697975143790245, 0.014848987571895123, 0.965184211730957, 0.8916692137718201, 0.9602262377738953, 0.009857614524662495, 0.009857614524662495, 0.9660462141036987, 0.009857614524662495, 0.028638238087296486, 0.9450618028640747, 0.9790526628494263, 0.010878362692892551, 0.9652154445648193, 0.08479874581098557, 0.932786226272583, 0.9288262724876404, 0.9823492169380188, 0.9437324404716492, 0.9798489212989807, 0.8981431126594543, 0.07698369026184082, 0.9277637600898743, 0.436313658952713, 0.03794031962752342, 0.01897015981376171, 0.09485079348087311, 0.41734349727630615, 0.9737067818641663, 0.47307443618774414, 0.5188558101654053, 0.8576308488845825, 0.9858759641647339, 0.8826650977134705, 0.09324490278959274, 0.18648980557918549, 0.6837959885597229, 0.031081635504961014, 0.9891363382339478, 0.959009051322937, 0.054671239107847214, 0.10934247821569443, 0.27335619926452637, 0.5467123985290527, 0.027335619553923607, 0.8549464344978333, 0.019396057352423668, 0.9310107827186584, 0.05818817391991615, 0.2083023637533188, 0.7290582656860352, 0.31531625986099243, 0.4335598349571228, 0.06897543370723724, 0.12809722125530243, 0.06897543370723724, 0.03992462530732155, 0.9182664155960083, 0.10732856392860413, 0.24532242119312286, 0.2759877145290375, 0.07666325569152832, 0.2913203835487366, 0.9513218998908997, 0.9459515810012817, 0.8747969269752502, 0.8603454232215881, 0.050101082772016525, 0.9519205689430237, 0.08121448010206223, 0.3248579204082489, 0.3790009319782257, 0.18950046598911285, 0.01804766245186329, 0.11771922558546066, 0.8711223006248474, 0.9292908906936646, 0.3028644919395447, 0.14461097121238708, 0.11186886578798294, 0.3383350968360901, 0.10368333756923676, 0.04319069907069206, 0.9501953721046448, 0.22918349504470825, 0.5013388991355896, 0.1718876212835312, 0.10026777535676956, 0.9285023212432861, 0.07176829874515533, 0.09892848134040833, 0.8903563022613525, 0.7464113831520081, 0.08113167434930801, 0.016226334497332573, 0.16226334869861603, 0.24535460770130157, 0.5850763916969299, 0.150987446308136, 0.018873430788517, 0.21083569526672363, 0.7730641961097717, 0.4201752543449402, 0.19772952795028687, 0.16683429479599, 0.0061790477484464645, 0.2162666767835617, 0.8995746374130249, 0.0599716417491436, 0.8533182740211487, 0.9592580199241638, 0.9095959067344666, 0.20529457926750183, 0.3927374482154846, 0.14727655053138733, 0.24099798500537872, 0.017851702868938446, 0.18447938561439514, 0.1623418629169464, 0.19923773407936096, 0.1475835144519806, 0.3173045516014099, 0.9391528964042664, 0.05494903773069382, 0.8242355585098267, 0.10989807546138763, 0.9759274125099182, 0.044171042740345, 0.0662565603852272, 0.044171042740345, 0.7950787544250488, 0.044171042740345, 0.055239275097846985, 0.7733498215675354, 0.16571782529354095, 0.3358133137226105, 0.1865629404783249, 0.44775107502937317, 0.027984442189335823, 0.009328147396445274, 0.9786370396614075, 0.9225075244903564, 0.32854166626930237, 0.14455834031105042, 0.14455834031105042, 0.07885000109672546, 0.28911668062210083, 0.5167816281318665, 0.018456485122442245, 0.11073891073465347, 0.018456485122442245, 0.35067322850227356, 0.8310382962226868, 0.8808777928352356, 0.12583968043327332, 0.9525858163833618, 0.2762085795402527, 0.5869432091712952, 0.017263036221265793, 0.034526072442531586, 0.08631517738103867], \"Term\": [\"'\", \"'\", \"'\", \"'\", \"absolutely\", \"acid\", \"actually\", \"actually\", \"actually\", \"actually\", \"add\", \"add\", \"add\", \"add\", \"add\", \"addict\", \"addition\", \"agree\", \"allergy\", \"allergy\", \"allergy\", \"amazon\", \"amazon\", \"amazon\", \"amazon\", \"artificial\", \"artificial\", \"artificial\", \"asian\", \"ask\", \"awful\", \"baby\", \"bad\", \"bad\", \"bad\", \"bad\", \"bad\", \"bag\", \"bag\", \"bag\", \"bag\", \"balance\", \"balance\", \"bar\", \"bean\", \"bean\", \"bean\", \"berry\", \"bitter\", \"black\", \"black\", \"bottle\", \"bottle\", \"bottle\", \"box\", \"box\", \"box\", \"box\", \"box\", \"brand\", \"brand\", \"brand\", \"brand\", \"brand\", \"break\", \"bring\", \"brown\", \"brown\", \"brown\", \"business\", \"butter\", \"butter\", \"butter\", \"butter\", \"buy\", \"buy\", \"buy\", \"buy\", \"buy\", \"c\", \"c\", \"caramel\", \"careful\", \"carry\", \"cat\", \"chemical\", \"cherry\", \"chicken\", \"child\", \"chip\", \"chip\", \"chip\", \"chocolate\", \"chocolate\", \"chocolate\", \"chocolate\", \"chocolate\", \"choose\", \"christmas\", \"christmas\", \"coffee\", \"coffee\", \"coffee\", \"coffee\", \"come\", \"come\", \"come\", \"come\", \"come\", \"consistency\", \"control\", \"cookie\", \"cookie\", \"cookie\", \"cookie\", \"cookie\", \"corn\", \"corn\", \"course\", \"course\", \"crisp\", \"crunch\", \"cup\", \"cup\", \"cup\", \"cup\", \"dad\", \"dairy\", \"date\", \"date\", \"date\", \"decide\", \"deep\", \"definitely\", \"definitely\", \"definitely\", \"delicious\", \"delicious\", \"delicious\", \"delicious\", \"delicious\", \"deliver\", \"deliver\", \"delivery\", \"different\", \"different\", \"different\", \"dinner\", \"disappoint\", \"dish\", \"dish\", \"drink\", \"drink\", \"drink\", \"drink\", \"drink\", \"dry\", \"dry\", \"earth\", \"earth\", \"earth\", \"earth\", \"earth\", \"easily\", \"eat\", \"eat\", \"eat\", \"eat\", \"eat\", \"enjoy\", \"enjoy\", \"exactly\", \"excellent\", \"excellent\", \"excellent\", \"expect\", \"expiration\", \"extract\", \"family\", \"family\", \"family\", \"family\", \"far\", \"fast\", \"father\", \"favorite\", \"favorite\", \"favorite\", \"favorite\", \"fiber\", \"finally\", \"find\", \"find\", \"find\", \"find\", \"find\", \"fine\", \"fine\", \"flavor\", \"flavor\", \"flavor\", \"flavor\", \"flavor\", \"flavour\", \"flour\", \"flour\", \"flour\", \"food\", \"food\", \"food\", \"food\", \"food\", \"fruit\", \"fruit\", \"fruit\", \"fruit\", \"fry\", \"fun\", \"fun\", \"get\", \"get\", \"get\", \"get\", \"get\", \"girl\", \"glad\", \"glad\", \"gluten\", \"gluten\", \"go\", \"go\", \"go\", \"go\", \"go\", \"good\", \"good\", \"good\", \"good\", \"good\", \"gourmet\", \"grab\", \"grain\", \"great\", \"great\", \"great\", \"great\", \"great\", \"green\", \"green\", \"green\", \"grow\", \"grow\", \"gum\", \"gum\", \"habanero\", \"heat\", \"heat\", \"heat\", \"high\", \"high\", \"high\", \"high\", \"high\", \"hit\", \"hold\", \"honey\", \"honey\", \"hope\", \"hot\", \"hot\", \"hot\", \"husband\", \"husband\", \"ice\", \"ingredient\", \"ingredient\", \"ingredient\", \"ingredient\", \"intake\", \"issue\", \"issue\", \"issue\", \"item\", \"item\", \"item\", \"item\", \"jar\", \"jar\", \"jar\", \"kettle\", \"kettle\", \"kettle\", \"kettle\", \"kettle\", \"kitchen\", \"kitchen\", \"know\", \"know\", \"know\", \"know\", \"know\", \"label\", \"label\", \"large\", \"large\", \"last\", \"leave\", \"like\", \"like\", \"like\", \"like\", \"like\", \"line\", \"little\", \"little\", \"little\", \"little\", \"little\", \"look\", \"look\", \"look\", \"look\", \"look\", \"lose\", \"lose\", \"love\", \"love\", \"love\", \"love\", \"love\", \"mean\", \"meat\", \"melt\", \"middle\", \"miss\", \"mix\", \"mix\", \"mix\", \"mix\", \"mom\", \"money\", \"month\", \"month\", \"month\", \"month\", \"mouth\", \"mouth\", \"msg\", \"nice\", \"nice\", \"nice\", \"night\", \"normally\", \"not\", \"not\", \"nut\", \"nutrition\", \"offer\", \"oil\", \"oil\", \"oil\", \"old\", \"old\", \"old\", \"old\", \"old\", \"one\", \"one\", \"one\", \"one\", \"one\", \"online\", \"open\", \"open\", \"open\", \"order\", \"order\", \"order\", \"order\", \"order\", \"organic\", \"organic\", \"organic\", \"ounce\", \"ounce\", \"ounce\", \"packaging\", \"pain\", \"peanut\", \"peanut\", \"peanut\", \"perfect\", \"perfect\", \"perfect\", \"personal\", \"piece\", \"plastic\", \"plastic\", \"plastic\", \"pop\", \"post\", \"pot\", \"potato\", \"potato\", \"potato\", \"power\", \"price\", \"price\", \"price\", \"price\", \"price\", \"process\", \"process\", \"product\", \"product\", \"product\", \"product\", \"product\", \"protein\", \"protein\", \"protein\", \"provide\", \"provide\", \"purchase\", \"purchase\", \"purchase\", \"purchase\", \"purchase\", \"quality\", \"quality\", \"quality\", \"quality\", \"quick\", \"real\", \"real\", \"receive\", \"recipe\", \"recommend\", \"recommend\", \"recommend\", \"recommend\", \"recommend\", \"red\", \"regularly\", \"remind\", \"remind\", \"reviewer\", \"rice\", \"rice\", \"rice\", \"roll\", \"salsa\", \"salt\", \"salt\", \"salt\", \"salt\", \"salty\", \"salty\", \"sauce\", \"sauce\", \"sea\", \"season\", \"season\", \"seller\", \"send\", \"service\", \"set\", \"ship\", \"ship\", \"shipment\", \"size\", \"size\", \"size\", \"size\", \"size\", \"smooth\", \"snack\", \"snack\", \"soak\", \"son\", \"soon\", \"soy\", \"soy\", \"soy\", \"soy\", \"spicy\", \"spot\", \"star\", \"star\", \"star\", \"star\", \"star\", \"steal\", \"stick\", \"stick\", \"stick\", \"stock\", \"stock\", \"store\", \"store\", \"store\", \"store\", \"store\", \"strawberry\", \"strawberry\", \"sugar\", \"sugar\", \"sugar\", \"sugar\", \"sugar\", \"suggest\", \"summer\", \"supermarket\", \"suppose\", \"surprised\", \"surprised\", \"sweet\", \"sweet\", \"sweet\", \"sweet\", \"sweet\", \"take\", \"take\", \"tart\", \"taste\", \"taste\", \"taste\", \"taste\", \"taste\", \"tasting\", \"tasting\", \"tasty\", \"tasty\", \"tasty\", \"tasty\", \"tea\", \"tea\", \"terrible\", \"terrible\", \"texture\", \"texture\", \"texture\", \"texture\", \"thank\", \"thank\", \"thank\", \"thank\", \"thin\", \"thin\", \"time\", \"time\", \"time\", \"time\", \"time\", \"tired\", \"tired\", \"ton\", \"tooth\", \"trip\", \"try\", \"try\", \"try\", \"try\", \"try\", \"use\", \"use\", \"use\", \"use\", \"use\", \"value\", \"vegetable\", \"vegetable\", \"vegetable\", \"version\", \"vinegar\", \"vinegar\", \"vinegar\", \"vinegar\", \"vinegar\", \"vitamin\", \"vitamin\", \"vitamin\", \"want\", \"want\", \"want\", \"want\", \"want\", \"waste\", \"watch\", \"water\", \"water\", \"water\", \"water\", \"water\", \"way\", \"way\", \"way\", \"way\", \"way\", \"website\", \"worth\", \"worth\", \"wrong\", \"year\", \"year\", \"year\", \"year\", \"year\"]}, \"R\": 30, \"lambda.step\": 0.01, \"plot.opts\": {\"xlab\": \"PC1\", \"ylab\": \"PC2\"}, \"topic.order\": [4, 2, 5, 3, 1]};\n",
       "\n",
       "function LDAvis_load_lib(url, callback){\n",
       "  var s = document.createElement('script');\n",
       "  s.src = url;\n",
       "  s.async = true;\n",
       "  s.onreadystatechange = s.onload = callback;\n",
       "  s.onerror = function(){console.warn(\"failed to load library \" + url);};\n",
       "  document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "}\n",
       "\n",
       "if(typeof(LDAvis) !== \"undefined\"){\n",
       "   // already loaded: just create the visualization\n",
       "   !function(LDAvis){\n",
       "       new LDAvis(\"#\" + \"ldavis_el74344756527602275292864\", ldavis_el74344756527602275292864_data);\n",
       "   }(LDAvis);\n",
       "}else if(typeof define === \"function\" && define.amd){\n",
       "   // require.js is available: use it to load d3/LDAvis\n",
       "   require.config({paths: {d3: \"https://cdnjs.cloudflare.com/ajax/libs/d3/3.5.5/d3.min\"}});\n",
       "   require([\"d3\"], function(d3){\n",
       "      window.d3 = d3;\n",
       "      LDAvis_load_lib(\"https://cdn.rawgit.com/bmabey/pyLDAvis/files/ldavis.v1.0.0.js\", function(){\n",
       "        new LDAvis(\"#\" + \"ldavis_el74344756527602275292864\", ldavis_el74344756527602275292864_data);\n",
       "      });\n",
       "    });\n",
       "}else{\n",
       "    // require.js not available: dynamically load d3 & LDAvis\n",
       "    LDAvis_load_lib(\"https://cdnjs.cloudflare.com/ajax/libs/d3/3.5.5/d3.min.js\", function(){\n",
       "         LDAvis_load_lib(\"https://cdn.rawgit.com/bmabey/pyLDAvis/files/ldavis.v1.0.0.js\", function(){\n",
       "                 new LDAvis(\"#\" + \"ldavis_el74344756527602275292864\", ldavis_el74344756527602275292864_data);\n",
       "            })\n",
       "         });\n",
       "}\n",
       "</script>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Visualize the topics\n",
    "pyLDAvis.enable_notebook()\n",
    "\n",
    "vis = pyLDAvis_gensim.prepare(lda_model, corpus, id2word, sort_topics=True)\n",
    "#lda_display = pyLDAvis.gensim.prepare(lda, corpus, dictionary, sort_topics=False)\n",
    "pyLDAvis.display(vis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
